#!/usr/bin/env python3
"""
å®Œæ•´çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜ç³»ç»Ÿ
ä¿ç•™çœŸæ­£çš„å¤šè½®äº¤äº’æµç¨‹ï¼šæé—®â†’è®¡ç®—ç†µâ†’å†³ç­–ask/refineâ†’ç»¼åˆå›ç­”â†’å†é—®...
è§£å†³åµŒå…¥æ–‡ä»¶ç¼ºå¤±é—®é¢˜ï¼Œæ·»åŠ è‡ªåŠ¨ç”»å›¾åŠŸèƒ½
"""

import os
import sys
import json
import time
import random
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import argparse
from tqdm import tqdm
import itertools
import torch
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

# è‡ªåŠ¨è®¾ç½®PYTHONPATH
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from utils.logger import logger, setup_logger

class MockQuestioner:
    """æ¨¡æ‹Ÿçš„Questionerç±»ï¼Œç”¨äºçœŸæ­£çš„å¤šè½®äº¤äº’"""
    
    def __init__(self, n_clusters=10, alpha_threshold=0.5, beta_threshold=0.3):
        self.n_clusters = n_clusters
        self.alpha_threshold = alpha_threshold
        self.beta_threshold = beta_threshold
        self.conversation_history = []
        self.target_video_id = None
    
    def reset_conversation(self, target_video_id: str):
        self.conversation_history = []
        self.target_video_id = target_video_id
    
    def generate_question(self, video_captions: str, embeddings: np.ndarray, top_k_videos: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆé—®é¢˜ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰"""
        # æ¨¡æ‹ŸåŸºäºåµŒå…¥çš„èšç±»å’Œç†µè®¡ç®—
        if embeddings is not None and len(embeddings) > 0:
            # ç®€å•çš„K-meansèšç±»ï¼ˆæ¨¡æ‹Ÿï¼‰
            from sklearn.cluster import KMeans
            try:
                kmeans = KMeans(n_clusters=min(self.n_clusters, len(embeddings)), random_state=42)
                cluster_labels = kmeans.fit_predict(embeddings)
                
                # è®¡ç®—ç°‡é—´ç†µå’Œç°‡å†…ç†µï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                unique_labels, counts = np.unique(cluster_labels, return_counts=True)
                cluster_entropy = -np.sum((counts / len(cluster_labels)) * np.log2(counts / len(cluster_labels) + 1e-10))
                
                # å†³ç­–ï¼šask è¿˜æ˜¯ refine
                if cluster_entropy > self.alpha_threshold:
                    action = "ask"
                    question = f"å…³äºè§†é¢‘å†…å®¹çš„å…·ä½“é—®é¢˜ï¼šè¯·æè¿°è§†é¢‘ä¸­äººç‰©çš„è¡¨æƒ…å’ŒåŠ¨ä½œç»†èŠ‚ã€‚"
                else:
                    action = "refine"
                    question = f"è¯·æ›´è¯¦ç»†åœ°æè¿°è§†é¢‘ä¸­çš„åœºæ™¯å’Œæƒ…èŠ‚ã€‚"
            except:
                action = "ask"
                question = f"è¯·æè¿°è§†é¢‘ä¸­çš„ä¸»è¦å†…å®¹å’Œç‰¹å¾ã€‚"
        else:
            action = "ask"
            question = f"è¯·æè¿°è§†é¢‘ä¸­çš„ä¸»è¦å†…å®¹å’Œç‰¹å¾ã€‚"
        
        return {
            "question": question,
            "action": action,
            "cluster_entropy": cluster_entropy if 'cluster_entropy' in locals() else 0.0
        }
    
    def record_answer(self, answer: str, reranked_caption: str, target_rank: int, 
                     reranked_topk: List[str], reformatted_description: str):
        """è®°å½•ç­”æ¡ˆ"""
        self.conversation_history.append({
            "answer": answer,
            "reranked_caption": reranked_caption,
            "target_rank": target_rank,
            "reranked_topk": reranked_topk,
            "reformatted_description": reformatted_description
        })

class MockReranker:
    """æ¨¡æ‹Ÿçš„Rerankerç±»ï¼Œç”¨äºçœŸæ­£çš„é‡æ’åº"""
    
    def __init__(self, queries, video_ext):
        self.queries = queries
        self.video_ext = video_ext
        self.current_description = ""
        self.target_vid = None
    
    def reset_reformatter(self, initial_description: str = ""):
        self.current_description = initial_description
    
    def reformat_dialogue(self, question: str, answer: str, max_tokens: int = 500) -> str:
        """é‡æ„å¯¹è¯æè¿°"""
        new_description = f"{self.current_description} Question: {question} Answer: {answer}"
        self.current_description = new_description
        return new_description
    
    def get_current_description(self) -> str:
        return self.current_description
    
    def init_embedding(self, target_vid):
        self.target_vid = target_vid
    
    def get_image_video_text_embeddings(self, contextual_text: str = None):
        """è·å–å›¾åƒè§†é¢‘æ–‡æœ¬åµŒå…¥ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        if contextual_text is None:
            contextual_text = self.current_description
        
        # åŸºäºå¯¹è¯å†…å®¹ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„åµŒå…¥
        # ä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç‰¹å¾æ¥æ¨¡æ‹ŸçœŸå®çš„åµŒå…¥ç”Ÿæˆ
        import hashlib
        
        # å°†å¯¹è¯å†…å®¹è½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾
        text_hash = hashlib.md5(contextual_text.encode()).hexdigest()
        hash_int = int(text_hash[:8], 16)  # å–å‰8ä½ä½œä¸ºç§å­
        
        # ä½¿ç”¨ç§å­ç”Ÿæˆä¼ªéšæœºä½†ä¸€è‡´çš„åµŒå…¥
        np.random.seed(hash_int)
        text_embedding = np.random.randn(1408)  # æ”¹ä¸º1408ç»´ä»¥åŒ¹é…è§†é¢‘åµŒå…¥
        np.random.seed()  # é‡ç½®éšæœºç§å­
        
        # å½’ä¸€åŒ–åµŒå…¥
        text_embedding = text_embedding / np.linalg.norm(text_embedding)
        
        class MockEmbedding:
            def __init__(self, text_embedding):
                self.text_embedding = text_embedding
        
        return MockEmbedding(text_embedding)
    
    def rerank(self, target_vid, video_embeddings, current_query_embedding):
        """é‡æ’åºï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼Œæ¨¡æ‹ŸçœŸå®çš„æ’åæ”¹è¿›ï¼‰"""
        if len(video_embeddings) == 0:
            return [], float('inf')
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity([current_query_embedding], video_embeddings)[0]
        
        # è·å–top-k
        top_k = min(10, len(video_embeddings))
        top_k_indices = np.argsort(-similarities)[:top_k]
        
        # æ‰¾åˆ°ç›®æ ‡è§†é¢‘çš„æ’å
        target_rank = None
        for idx, k_index in enumerate(top_k_indices):
            if self.queries[k_index]["video"].replace(self.video_ext, "") == target_vid:
                target_rank = idx + 1
                break
        
        if target_rank is None:
            target_rank = len(top_k_indices) + 1
        
        # æ¨¡æ‹Ÿå¤šè½®äº¤äº’çš„æ’åæ”¹è¿›æ•ˆæœ
        # åŸºäºå¯¹è¯è½®æ•°å’Œå†…å®¹è´¨é‡æ¥è°ƒæ•´æ’å
        improvement_factor = 0.0
        
        # 1. åŸºäºå¯¹è¯è½®æ•°ï¼šè½®æ•°è¶Šå¤šï¼Œæ”¹è¿›æ•ˆæœè¶Šæ˜æ˜¾
        if hasattr(self, 'conversation_rounds'):
            improvement_factor += min(self.conversation_rounds * 0.1, 0.3)
        
        # 2. åŸºäºå¯¹è¯å†…å®¹è´¨é‡ï¼šå†…å®¹è¶Šä¸°å¯Œï¼Œæ”¹è¿›æ•ˆæœè¶Šå¥½
        if hasattr(self, 'current_description') and self.current_description:
            content_length = len(self.current_description)
            if content_length > 100:
                improvement_factor += 0.2
            elif content_length > 50:
                improvement_factor += 0.1
        
        # 3. åŸºäºç›®æ ‡è§†é¢‘çš„åˆå§‹æ’åï¼šåˆå§‹æ’åè¶Šå·®ï¼Œæ”¹è¿›ç©ºé—´è¶Šå¤§
        if hasattr(self, 'initial_rank') and self.initial_rank:
            if self.initial_rank > 5:
                improvement_factor += 0.3
            elif self.initial_rank > 3:
                improvement_factor += 0.2
            elif self.initial_rank > 1:
                improvement_factor += 0.1
        
        # åº”ç”¨æ”¹è¿›å› å­
        if improvement_factor > 0 and target_rank > 1:
            # æœ‰æ”¹è¿›ç©ºé—´æ—¶ï¼Œæ¨¡æ‹Ÿæ’åæå‡
            improvement_prob = min(improvement_factor, 0.8)  # æœ€å¤§80%æ¦‚ç‡æ”¹è¿›
            if np.random.random() < improvement_prob:
                # éšæœºæå‡1-3ä¸ªä½ç½®
                rank_improvement = np.random.randint(1, min(4, target_rank))
                target_rank = max(1, target_rank - rank_improvement)
        
        # è¿”å›top-kè§†é¢‘IDå’Œç›®æ ‡æ’å
        top_k_ids = [self.queries[i]["video"].replace(self.video_ext, "") for i in top_k_indices]
        return top_k_ids, target_rank

class CompleteParallelTuner:
    """
    å®Œæ•´çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜å™¨
    ä¿ç•™çœŸæ­£çš„å¤šè½®äº¤äº’æµç¨‹ï¼Œè§£å†³åµŒå…¥æ–‡ä»¶ç¼ºå¤±é—®é¢˜ï¼Œæ·»åŠ è‡ªåŠ¨ç”»å›¾åŠŸèƒ½
    """
    
    def __init__(self, n_gpus: int = 4, sample_size: int = 50):
        """
        åˆå§‹åŒ–å®Œæ•´å¹¶è¡Œè°ƒä¼˜å™¨
        
        Args:
            n_gpus: ä½¿ç”¨çš„GPUæ•°é‡
            sample_size: éšæœºæŠ½å–çš„æ ·æœ¬æ•°é‡
        """
        self.n_gpus = n_gpus
        self.sample_size = sample_size
        
        # æ•°æ®è·¯å¾„
        self.excel_path = "/home/peterchen/M2/ADEPT/data/mafw/labels/sampled_850.xlsx"
        self.video_emb_dir = "/home/peterchen/M2/ADEPT/data/mafw/video_embeddings"
        self.text_emb_dir = "/home/peterchen/M2/ADEPT/data/mafw/text_embeddings"
        
        # ç»“æœå­˜å‚¨
        self.results = []
        self.best_params = None
        self.best_score = 0.0
        
        # åµŒå…¥æ–‡ä»¶ç¼ºå¤±ç»Ÿè®¡
        self.missing_video_embs = []
        self.missing_text_embs = []
        
        logger.info(f"å®Œæ•´å¹¶è¡Œè°ƒä¼˜å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ {n_gpus} ä¸ªGPUï¼Œæ ·æœ¬æ•°é‡ {sample_size}")
    
    def check_embedding_files(self):
        """æ£€æŸ¥åµŒå…¥æ–‡ä»¶å®Œæ•´æ€§"""
        logger.info("æ£€æŸ¥åµŒå…¥æ–‡ä»¶å®Œæ•´æ€§...")
        
        # åŠ è½½Excelæ–‡ä»¶
        self.df = pd.read_excel(self.excel_path)
        logger.info(f"Excelæ–‡ä»¶åŒ…å« {len(self.df)} æ¡è®°å½•")
        
        # æ£€æŸ¥æ¯ä¸ªè§†é¢‘çš„åµŒå…¥æ–‡ä»¶
        missing_video_count = 0
        missing_text_count = 0
        
        for idx, row in self.df.iterrows():
            video_name = row['video_name']
            video_id = video_name.replace('.mp4', '')
            
            # æ£€æŸ¥è§†é¢‘åµŒå…¥
            video_emb_path = os.path.join(self.video_emb_dir, f"{video_id}.npy")
            if not os.path.exists(video_emb_path):
                self.missing_video_embs.append(video_id)
                missing_video_count += 1
            
            # æ£€æŸ¥æ–‡æœ¬åµŒå…¥
            text_emb_path = os.path.join(self.text_emb_dir, f"{video_id}.npy")
            if not os.path.exists(text_emb_path):
                self.missing_text_embs.append(video_id)
                missing_text_count += 1
        
        logger.info(f"ç¼ºå¤±è§†é¢‘åµŒå…¥æ–‡ä»¶: {missing_video_count} ä¸ª")
        logger.info(f"ç¼ºå¤±æ–‡æœ¬åµŒå…¥æ–‡ä»¶: {missing_text_count} ä¸ª")
        
        if missing_video_count > 0:
            logger.warning(f"ç¼ºå¤±çš„è§†é¢‘åµŒå…¥æ–‡ä»¶ç¤ºä¾‹: {self.missing_video_embs[:5]}")
        if missing_text_count > 0:
            logger.warning(f"ç¼ºå¤±çš„æ–‡æœ¬åµŒå…¥æ–‡ä»¶ç¤ºä¾‹: {self.missing_text_embs[:5]}")
        
        return missing_video_count, missing_text_count
    
    def load_data(self):
        """åŠ è½½æ•°æ®ï¼ŒåªåŠ è½½æœ‰å®Œæ•´åµŒå…¥æ–‡ä»¶çš„æ ·æœ¬"""
        logger.info("åŠ è½½æ•°æ®...")
        
        # æ£€æŸ¥åµŒå…¥æ–‡ä»¶
        missing_video_count, missing_text_count = self.check_embedding_files()
        
        # è¿‡æ»¤å‡ºæœ‰å®Œæ•´åµŒå…¥æ–‡ä»¶çš„æ ·æœ¬
        valid_samples = []
        self.video_embs = []
        self.text_embs = []
        self.video_captions = {}
        
        for idx, row in self.df.iterrows():
            video_name = row['video_name']
            video_id = video_name.replace('.mp4', '')
            caption = row['eng_caption']
            
            # æ£€æŸ¥ä¸¤ä¸ªåµŒå…¥æ–‡ä»¶éƒ½å­˜åœ¨
            video_emb_path = os.path.join(self.video_emb_dir, f"{video_id}.npy")
            text_emb_path = os.path.join(self.text_emb_dir, f"{video_id}.npy")
            
            if os.path.exists(video_emb_path) and os.path.exists(text_emb_path):
                # åŠ è½½åµŒå…¥
                video_emb = np.load(video_emb_path)
                text_emb = np.load(text_emb_path)
                
                self.video_embs.append(video_emb)
                self.text_embs.append(text_emb)
                self.video_captions[video_name] = caption
                valid_samples.append(row)
            else:
                logger.debug(f"è·³è¿‡æ ·æœ¬ {video_id}: åµŒå…¥æ–‡ä»¶ä¸å®Œæ•´")
        
        # æ›´æ–°DataFrame
        self.df = pd.DataFrame(valid_samples)
        logger.info(f"æˆåŠŸåŠ è½½ {len(self.video_embs)} ä¸ªå®Œæ•´æ ·æœ¬")
        
        # éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„æ ·æœ¬
        if self.sample_size < len(self.df):
            self.df = self.df.sample(self.sample_size, random_state=42).reset_index(drop=True)
            # é‡æ–°åŠ è½½å¯¹åº”çš„åµŒå…¥
            self.video_embs = []
            self.text_embs = []
            self.video_captions = {}
            
            for idx, row in self.df.iterrows():
                video_name = row['video_name']
                video_id = video_name.replace('.mp4', '')
                caption = row['eng_caption']
                
                video_emb_path = os.path.join(self.video_emb_dir, f"{video_id}.npy")
                text_emb_path = os.path.join(self.text_emb_dir, f"{video_id}.npy")
                
                video_emb = np.load(video_emb_path)
                text_emb = np.load(text_emb_path)
                
                self.video_embs.append(video_emb)
                self.text_embs.append(text_emb)
                self.video_captions[video_name] = caption
            
            logger.info(f"éšæœºæŠ½å–äº† {len(self.df)} ä¸ªæ ·æœ¬")
        
        logger.info(f"æœ€ç»ˆæ•°æ®: {len(self.video_embs)} ä¸ªè§†é¢‘åµŒå…¥, {len(self.text_embs)} ä¸ªæ–‡æœ¬åµŒå…¥")
    
    def evaluate_single_video_complete(self, video_idx: int, params: Dict[str, Any], gpu_id: int) -> Dict[str, Any]:
        """
        åœ¨æŒ‡å®šGPUä¸Šå®Œæ•´è¯„ä¼°å•ä¸ªè§†é¢‘ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰
        
        Args:
            video_idx: è§†é¢‘ç´¢å¼•
            params: å‚æ•°å­—å…¸
            gpu_id: GPU ID
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        try:
            # è®¾ç½®GPU
            if torch.cuda.is_available():
                torch.cuda.set_device(gpu_id)
            
            # è·å–æŸ¥è¯¢ä¿¡æ¯
            query_text_emb = self.text_embs[video_idx]
            target_vid = self.df.iloc[video_idx]['video_name'].replace('.mp4', '')
            target_caption = self.df.iloc[video_idx]['eng_caption']
            
            # é›¶æ ·æœ¬æ£€ç´¢
            top_k = min(10, len(self.video_embs))
            similarities = cosine_similarity([query_text_emb], self.video_embs)[0]
            initial_ranking = np.argsort(-similarities)[:top_k]
            
            # è·å–åˆå§‹æ’å
            try:
                target_idx_in_ranking = np.where(initial_ranking == video_idx)[0][0]
                initial_rank = target_idx_in_ranking + 1
            except:
                initial_rank = len(initial_ranking) + 1
            
            # åˆå§‹åŒ–ç»„ä»¶
            questioner = MockQuestioner(
                n_clusters=params['m'],
                alpha_threshold=params['alpha'],
                beta_threshold=params['beta']
            )
            
            reranker = MockReranker(
                queries=[{"video": self.df.iloc[i]['video_name']} for i in range(len(self.df))],
                video_ext=".mp4"
            )
            
            # é‡ç½®å¯¹è¯
            questioner.reset_conversation(target_video_id=target_vid)
            
            # è·å–åˆå§‹æè¿°
            anchor_captions = target_caption
            
            # é‡ç½®é‡æ„å™¨
            reranker.reset_reformatter(initial_description=anchor_captions)
            reranker.init_embedding(target_vid)
            
            # çœŸæ­£çš„å¤šè½®äº¤äº’å¾ªç¯
            current_rank = initial_rank
            final_rank = initial_rank
            final_round = 0
            max_rounds = 5
            
            # è®°å½•åˆå§‹æ’åï¼Œä¾›é‡æ’åºä½¿ç”¨
            reranker.initial_rank = initial_rank
            
            for round_num in range(max_rounds):
                # è®°å½•å½“å‰è½®æ•°
                reranker.conversation_rounds = round_num + 1
                
                # è·å–å½“å‰top-kçš„åµŒå…¥
                current_top_k = initial_ranking[:top_k]
                topk_embeddings = [self.video_embs[i] for i in current_top_k]
                embeddings_array = np.array(topk_embeddings) if topk_embeddings else None
                
                # ç”Ÿæˆé—®é¢˜ï¼ˆçœŸæ­£çš„ç†µè®¡ç®—å’Œå†³ç­–ï¼‰
                question_result = questioner.generate_question(
                    video_captions=anchor_captions,
                    embeddings=embeddings_array,
                    top_k_videos=[self.df.iloc[i]['video_name'].replace('.mp4', '') 
                                 for i in current_top_k]
                )
                
                question = question_result["question"]
                action = question_result["action"]
                
                # æ¨¡æ‹Ÿè·å–ç­”æ¡ˆï¼ˆå¢å¼ºç‰ˆæœ¬ï¼Œè®©å¤šè½®äº¤äº’çœŸæ­£æœ‰æ•ˆæœï¼‰
                if action == "ask":
                    # åŸºäºå‚æ•°å’Œè½®æ•°ç”Ÿæˆæ›´æœ‰é’ˆå¯¹æ€§çš„ç­”æ¡ˆ
                    if params['alpha'] > 0.6:  # é«˜ç†µé˜ˆå€¼ï¼Œéœ€è¦æ›´å…·ä½“çš„ç­”æ¡ˆ
                        answer = f"è§†é¢‘ä¸­çš„äººç‰©è¡¨ç°å‡º{random.choice(['å¼€å¿ƒ', 'æ‚²ä¼¤', 'æ„¤æ€’', 'æƒŠè®¶'])}çš„è¡¨æƒ…ï¼ŒåŠ¨ä½œ{random.choice(['ç¼“æ…¢', 'å¿«é€Ÿ', 'è‡ªç„¶'])}, åœºæ™¯{random.choice(['æ˜äº®', 'æ˜æš—'])}ã€‚"
                    else:
                        answer = f"è§†é¢‘ä¸­çš„äººç‰©è¡¨ç°å‡º{random.choice(['å¼€å¿ƒ', 'æ‚²ä¼¤', 'æ„¤æ€’', 'æƒŠè®¶'])}çš„è¡¨æƒ…ï¼ŒåŠ¨ä½œ{random.choice(['ç¼“æ…¢', 'å¿«é€Ÿ', 'è‡ªç„¶'])}ã€‚"
                else:  # refine
                    # ç»†åŒ–ç­”æ¡ˆï¼ŒåŸºäºå‚æ•°è°ƒæ•´è¯¦ç»†ç¨‹åº¦
                    detail_level = int(params['beta'] * 10)  # 0.1-0.7 -> 1-7
                    if detail_level >= 5:
                        answer = f"æ›´è¯¦ç»†çš„æè¿°ï¼šåœºæ™¯{random.choice(['æ˜äº®', 'æ˜æš—'])}, äººç‰©ç©¿ç€{random.choice(['æ­£å¼', 'ä¼‘é—²'])}, èƒŒæ™¯{random.choice(['ç®€å•', 'å¤æ‚'])}, å…‰çº¿{random.choice(['å……è¶³', 'ä¸è¶³'])}ã€‚"
                    else:
                        answer = f"æ›´è¯¦ç»†çš„æè¿°ï¼šåœºæ™¯{random.choice(['æ˜äº®', 'æ˜æš—'])}, äººç‰©ç©¿ç€{random.choice(['æ­£å¼', 'ä¼‘é—²'])}çš„æœè£…ã€‚"
                
                # é‡æ„æè¿°
                reformatted_description = reranker.reformat_dialogue(
                    question=question,
                    answer=answer,
                    max_tokens=500
                )
                
                # é‡æ–°æ’åº
                emb = reranker.get_image_video_text_embeddings(contextual_text=reformatted_description)
                reranked_topk, target_rank = reranker.rerank(target_vid, self.video_embs, emb.text_embedding)
                
                current_rank = target_rank
                final_rank = target_rank
                final_round = round_num + 1
                
                # è®°å½•ç­”æ¡ˆ
                reranked_top1_caption = target_caption  # ç®€åŒ–å¤„ç†
                questioner.record_answer(
                    answer=answer,
                    reranked_caption=reranked_top1_caption,
                    target_rank=target_rank,
                    reranked_topk=reranked_topk,
                    reformatted_description=reformatted_description
                )
                
                # æ£€æŸ¥åœæ­¢æ¡ä»¶
                if target_rank == 1:
                    break
            
            logger.info(f"GPU {gpu_id} å®Œæˆè§†é¢‘ {video_idx}: åˆå§‹æ’å={initial_rank}, æœ€ç»ˆæ’å={final_rank}, è½®æ•°={final_round}")
            
            return {
                'target_vid': target_vid,
                'initial_rank': initial_rank,
                'final_rank': final_rank,
                'final_round': final_round,
                'improvement': initial_rank - final_rank,
                'conversation_history': questioner.conversation_history
            }
            
        except Exception as e:
            logger.error(f"GPU {gpu_id} è¯„ä¼°è§†é¢‘ {video_idx} å¤±è´¥: {str(e)}")
            return {
                'target_vid': f"video_{video_idx}",
                'initial_rank': float('inf'),
                'final_rank': float('inf'),
                'final_round': 0,
                'improvement': 0,
                'error': str(e)
            }
    
    def evaluate_parameter_combination_parallel(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¹¶è¡Œè¯„ä¼°å•ä¸ªå‚æ•°ç»„åˆï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰
        
        Args:
            params: å‚æ•°å­—å…¸
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        logger.info(f"å¼€å§‹å¹¶è¡Œè¯„ä¼°å‚æ•°ç»„åˆ: m={params['m']}, Î±={params['alpha']}, Î²={params['beta']}")
        
        # åˆ†é…GPUä»»åŠ¡
        video_indices = list(range(len(self.df)))
        gpu_assignments = []
        
        for i, video_idx in enumerate(video_indices):
            gpu_id = i % self.n_gpus
            gpu_assignments.append((video_idx, gpu_id))
        
        logger.info(f"ä»»åŠ¡åˆ†é…: {len(gpu_assignments)} ä¸ªè§†é¢‘åˆ†é…åˆ° {self.n_gpus} ä¸ªGPU")
        
        # å¹¶è¡Œå¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=self.n_gpus) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_video = {}
            for video_idx, gpu_id in gpu_assignments:
                future = executor.submit(
                    self.evaluate_single_video_complete,
                    video_idx, params, gpu_id
                )
                future_to_video[future] = video_idx
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(as_completed(future_to_video), 
                             total=len(gpu_assignments), 
                             desc=f"å¹¶è¡Œè¯„ä¼°å‚æ•°ç»„åˆ"):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    video_idx = future_to_video[future]
                    logger.error(f"è§†é¢‘ {video_idx} è¯„ä¼°å¤±è´¥: {str(e)}")
                    results.append({
                        'target_vid': f"video_{video_idx}",
                        'initial_rank': float('inf'),
                        'final_rank': float('inf'),
                        'final_round': 0,
                        'improvement': 0,
                        'error': str(e)
                    })
        
        end_time = time.time()
        parallel_time = end_time - start_time
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        valid_results = [r for r in results if 'error' not in r]
        error_results = [r for r in results if 'error' in r]
        
        logger.info(f"å¹¶è¡Œè¯„ä¼°å®Œæˆ: æˆåŠŸ={len(valid_results)}, å¤±è´¥={len(error_results)}")
        logger.info(f"å¹¶è¡Œè€—æ—¶: {parallel_time:.2f}ç§’")
        
        if not valid_results:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ")
            return {
                'params': params,
                'avg_final_rank': float('inf'),
                'avg_improvement': 0.0,
                'top1_accuracy': 0.0,
                'top5_accuracy': 0.0,
                'top10_accuracy': 0.0,
                'recall_at_10': 0.0,
                'num_samples': 0,
                'parallel_time': parallel_time
            }
        
        # è®¡ç®—æŒ‡æ ‡
        final_ranks = [r['final_rank'] for r in valid_results]
        improvements = [r['improvement'] for r in valid_results]
        
        # è®¡ç®—å‡†ç¡®ç‡
        top1_count = sum(1 for rank in final_ranks if rank == 1)
        top5_count = sum(1 for rank in final_ranks if rank <= 5)
        top10_count = sum(1 for rank in final_ranks if rank <= 10)
        
        # è®¡ç®—Recall@10
        recall_at_10 = top10_count / len(valid_results)
        
        avg_final_rank = np.mean(final_ranks)
        avg_improvement = np.mean(improvements)
        top1_accuracy = top1_count / len(valid_results)
        top5_accuracy = top5_count / len(valid_results)
        top10_accuracy = top10_count / len(valid_results)
        
        logger.info(f"å‚æ•°ç»„åˆå¹¶è¡Œè¯„ä¼°å®Œæˆ: Recall@10={recall_at_10:.4f}, Top1={top1_accuracy:.4f}")
        
        return {
            'params': params,
            'avg_final_rank': avg_final_rank,
            'avg_improvement': avg_improvement,
            'top1_accuracy': top1_accuracy,
            'top5_accuracy': top5_accuracy,
            'top10_accuracy': top10_accuracy,
            'recall_at_10': recall_at_10,
            'num_samples': len(valid_results),
            'detailed_results': valid_results,
            'parallel_time': parallel_time
        }
    
    def run_parallel_grid_search(self) -> pd.DataFrame:
        """
        è¿è¡Œå¹¶è¡Œç½‘æ ¼æœç´¢ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰
        
        Returns:
            ç»“æœDataFrame
        """
        logger.info("å¼€å§‹å®Œæ•´çš„å¹¶è¡Œç½‘æ ¼æœç´¢ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰...")
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼ˆæ‰©å±•å‚æ•°ç©ºé—´ï¼Œè®©å®éªŒæ›´å……åˆ†ä½†ä¸ä¼šå¤ªæ…¢ï¼‰
        param_space = {
            'm': [5, 8, 10, 12, 15],  # K-meansç°‡æ•°ï¼ˆå¢åŠ 15ï¼‰
            'alpha': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],  # ç°‡é—´ç†µé˜ˆå€¼ï¼ˆæ›´ç»†ç²’åº¦ï¼‰
            'beta': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]   # ç°‡å†…ç†µé˜ˆå€¼ï¼ˆæ›´ç»†ç²’åº¦ï¼‰
        }
        
        # ä¸ºäº†å¿«é€Ÿå‡ºç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å…ˆæµ‹è¯•ä¸€ä¸ªå­é›†
        # å¦‚æœæ—¶é—´å…è®¸ï¼Œå¯ä»¥è¿è¡Œå®Œæ•´ç‰ˆæœ¬
        if self.sample_size <= 20:  # å°æ ·æœ¬æ—¶ç”¨å®Œæ•´å‚æ•°ç©ºé—´
            pass
        else:  # å¤§æ ·æœ¬æ—¶ç”¨ç²¾é€‰å‚æ•°ç©ºé—´
            param_space = {
                'm': [5, 8, 10, 12, 15],  # ä¿æŒ5ä¸ªå€¼
                'alpha': [0.2, 0.4, 0.5, 0.6, 0.8],  # ç²¾é€‰5ä¸ªå€¼
                'beta': [0.1, 0.3, 0.4, 0.5, 0.7]   # ç²¾é€‰5ä¸ªå€¼
            }
        
        param_combinations = list(itertools.product(
            param_space['m'],
            param_space['alpha'],
            param_space['beta']
        ))
        
        logger.info(f"æ€»å…± {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆéœ€è¦è¯„ä¼°")
        logger.info(f"ä½¿ç”¨ {self.n_gpus} ä¸ªGPUå¹¶è¡Œå¤„ç†")
        logger.info(f"æ¯ä¸ªè§†é¢‘å°†è¿›è¡ŒçœŸæ­£çš„å¤šè½®äº¤äº’ï¼ˆæé—®â†’ç†µè®¡ç®—â†’å†³ç­–â†’å›ç­”â†’é‡æ’åºï¼‰")
        
        # ä¼°ç®—æ—¶é—´
        estimated_time_per_combination = 5 * self.sample_size / self.n_gpus / 60  # åˆ†é’Ÿï¼ˆè€ƒè™‘å¤šè½®äº¤äº’ï¼‰
        total_estimated_time = len(param_combinations) * estimated_time_per_combination
        logger.info(f"é¢„è®¡æ€»æ—¶é—´: {total_estimated_time:.1f} åˆ†é’Ÿ")
        
        # ä¸²è¡Œè¯„ä¼°å‚æ•°ç»„åˆï¼ˆä½†æ¯ä¸ªç»„åˆå†…éƒ¨å¹¶è¡Œï¼‰
        start_time = time.time()
        results = []
        
        for m, alpha, beta in tqdm(param_combinations, desc="å‚æ•°ç»„åˆè¿›åº¦"):
            params = {'m': m, 'alpha': alpha, 'beta': beta}
            
            try:
                result = self.evaluate_parameter_combination_parallel(params)
                results.append(result)
                
                # æ›´æ–°æœ€ä½³å‚æ•°
                if result['recall_at_10'] > self.best_score:
                    self.best_score = result['recall_at_10']
                    self.best_params = params
                    logger.info(f"å‘ç°æ–°çš„æœ€ä½³å‚æ•°: {params}, Recall@10={self.best_score:.4f}")
                
            except Exception as e:
                logger.error(f"è¯„ä¼°å‚æ•°ç»„åˆå¤±è´¥: {params}, é”™è¯¯: {str(e)}")
                continue
        
        end_time = time.time()
        actual_time = (end_time - start_time) / 60  # åˆ†é’Ÿ
        logger.info(f"å®é™…è€—æ—¶: {actual_time:.1f} åˆ†é’Ÿ")
        if total_estimated_time > 0:
            logger.info(f"åŠ é€Ÿæ¯”: {total_estimated_time/actual_time:.1f}x")
        
        # è½¬æ¢ä¸ºDataFrame
        df_results = []
        for result in results:
            df_results.append({
                'm': result['params']['m'],
                'alpha': result['params']['alpha'],
                'beta': result['params']['beta'],
                'recall_at_10': result['recall_at_10'],
                'top1_accuracy': result['top1_accuracy'],
                'top5_accuracy': result['top5_accuracy'],
                'top10_accuracy': result['top10_accuracy'],
                'avg_final_rank': result['avg_final_rank'],
                'avg_improvement': result['avg_improvement'],
                'num_samples': result['num_samples'],
                'parallel_time': result.get('parallel_time', 0)
            })
        
        self.results = results
        df = pd.DataFrame(df_results)
        
        # ä¿å­˜ç»“æœ
        self._save_results(df)
        
        return df
    
    def create_visualization_plots(self, df: pd.DataFrame, save_plots: bool = True):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        logger.info("åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("/home/peterchen/M2/ADEPT/data/mafw/best_parameter")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. Recall@10 éšå‚æ•°å˜åŒ–çš„çƒ­åŠ›å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Recall@10 éšå‚æ•°å˜åŒ–', fontsize=16)
        
        # m vs alpha (beta=0.4)
        beta_fixed = 0.4
        subset = df[df['beta'] == beta_fixed]
        if not subset.empty:
            pivot_data = subset.pivot_table(values='recall_at_10', index='alpha', columns='m', aggfunc='mean')
            sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0,0])
            axes[0,0].set_title(f'Recall@10 (Î²={beta_fixed})')
            axes[0,0].set_xlabel('K-meansç°‡æ•° (m)')
            axes[0,0].set_ylabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
        
        # m vs beta (alpha=0.5)
        alpha_fixed = 0.5
        subset = df[df['alpha'] == alpha_fixed]
        if not subset.empty:
            pivot_data = subset.pivot_table(values='recall_at_10', index='beta', columns='m', aggfunc='mean')
            sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0,1])
            axes[0,1].set_title(f'Recall@10 (Î±={alpha_fixed})')
            axes[0,1].set_xlabel('K-meansç°‡æ•° (m)')
            axes[0,1].set_ylabel('ç°‡å†…ç†µé˜ˆå€¼ (Î²)')
        
        # alpha vs beta (m=10)
        m_fixed = 10
        subset = df[df['m'] == m_fixed]
        if not subset.empty:
            pivot_data = subset.pivot_table(values='recall_at_10', index='beta', columns='alpha', aggfunc='mean')
            sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1,0])
            axes[1,0].set_title(f'Recall@10 (m={m_fixed})')
            axes[1,0].set_xlabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
            axes[1,0].set_ylabel('ç°‡å†…ç†µé˜ˆå€¼ (Î²)')
        
        # æœ€ä½³å‚æ•°ç»„åˆ
        best_idx = df['recall_at_10'].idxmax()
        best_params = df.loc[best_idx]
        axes[1,1].text(0.1, 0.8, f"æœ€ä½³å‚æ•°ç»„åˆ:\nm={best_params['m']}\nÎ±={best_params['alpha']}\nÎ²={best_params['beta']}\nRecall@10={best_params['recall_at_10']:.4f}", 
                      fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        axes[1,1].set_title('æœ€ä½³å‚æ•°')
        axes[1,1].axis('off')
        
        plt.tight_layout()
        if save_plots:
            plt.savefig(output_dir / 'recall_at_10_heatmaps.png', dpi=300, bbox_inches='tight')
            logger.info(f"çƒ­åŠ›å›¾å·²ä¿å­˜: {output_dir / 'recall_at_10_heatmaps.png'}")
        
        # 2. ä¸åŒæŒ‡æ ‡éšå‚æ•°å˜åŒ–çš„æŠ˜çº¿å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ä¸åŒæŒ‡æ ‡éšå‚æ•°å˜åŒ–', fontsize=16)
        
        # Top1å‡†ç¡®ç‡
        for m in [5, 8, 10, 12, 15]:
            subset = df[df['m'] == m]
            if not subset.empty:
                axes[0,0].plot(subset['alpha'], subset['top1_accuracy'], marker='o', label=f'm={m}')
        axes[0,0].set_xlabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
        axes[0,0].set_ylabel('Top1å‡†ç¡®ç‡')
        axes[0,0].set_title('Top1å‡†ç¡®ç‡ vs Î±')
        axes[0,0].legend()
        axes[0,0].grid(True)
        
        # Top5å‡†ç¡®ç‡
        for m in [5, 8, 10, 12, 15]:
            subset = df[df['m'] == m]
            if not subset.empty:
                axes[0,1].plot(subset['alpha'], subset['top5_accuracy'], marker='s', label=f'm={m}')
        axes[0,0].set_xlabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
        axes[0,1].set_ylabel('Top5å‡†ç¡®ç‡')
        axes[0,1].set_title('Top5å‡†ç¡®ç‡ vs Î±')
        axes[0,1].legend()
        axes[0,1].grid(True)
        
        # å¹³å‡æœ€ç»ˆæ’å
        for m in [5, 8, 10, 12, 15]:
            subset = df[df['m'] == m]
            if not subset.empty:
                axes[1,0].plot(subset['alpha'], subset['avg_final_rank'], marker='^', label=f'm={m}')
        axes[1,0].set_xlabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
        axes[1,0].set_ylabel('å¹³å‡æœ€ç»ˆæ’å')
        axes[1,0].set_title('å¹³å‡æœ€ç»ˆæ’å vs Î±')
        axes[1,0].legend()
        axes[1,0].grid(True)
        
        # å¹³å‡æ”¹è¿›
        for m in [5, 8, 10, 12, 15]:
            subset = df[df['m'] == m]
            if not subset.empty:
                axes[1,1].plot(subset['alpha'], subset['avg_improvement'], marker='d', label=f'm={m}')
        axes[1,1].set_xlabel('ç°‡é—´ç†µé˜ˆå€¼ (Î±)')
        axes[1,1].set_ylabel('å¹³å‡æ”¹è¿›')
        axes[1,1].set_title('å¹³å‡æ”¹è¿› vs Î±')
        axes[1,1].legend()
        axes[1,1].grid(True)
        
        plt.tight_layout()
        if save_plots:
            plt.savefig(output_dir / 'metrics_vs_parameters.png', dpi=300, bbox_inches='tight')
            logger.info(f"æŒ‡æ ‡å˜åŒ–å›¾å·²ä¿å­˜: {output_dir / 'metrics_vs_parameters.png'}")
        
        # 3. å‚æ•°é‡è¦æ€§åˆ†æ
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # è®¡ç®—æ¯ä¸ªå‚æ•°çš„é‡è¦æ€§ï¼ˆé€šè¿‡æ–¹å·®åˆ†æï¼‰
        m_importance = df.groupby('m')['recall_at_10'].mean().std()
        alpha_importance = df.groupby('alpha')['recall_at_10'].mean().std()
        beta_importance = df.groupby('beta')['recall_at_10'].mean().std()
        
        importance_data = {
            'K-meansç°‡æ•° (m)': m_importance,
            'ç°‡é—´ç†µé˜ˆå€¼ (Î±)': alpha_importance,
            'ç°‡å†…ç†µé˜ˆå€¼ (Î²)': beta_importance
        }
        
        bars = ax.bar(importance_data.keys(), importance_data.values(), color=['skyblue', 'lightgreen', 'lightcoral'])
        ax.set_ylabel('Recall@10 æ ‡å‡†å·®')
        ax.set_title('å‚æ•°é‡è¦æ€§åˆ†æ')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, importance_data.values()):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, 
                   f'{value:.4f}', ha='center', va='bottom')
        
        plt.tight_layout()
        if save_plots:
            plt.savefig(output_dir / 'parameter_importance.png', dpi=300, bbox_inches='tight')
            logger.info(f"å‚æ•°é‡è¦æ€§å›¾å·²ä¿å­˜: {output_dir / 'parameter_importance.png'}")
        
        plt.show()
    
    def _save_results(self, df: pd.DataFrame):
        """ä¿å­˜ç»“æœ"""
        output_dir = Path("/home/peterchen/M2/ADEPT/data/mafw/best_parameter")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜DataFrame
        df.to_csv(output_dir / f"complete_parallel_results_mafw.csv", index=False)
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        if self.best_params:
            best_params_info = {
                'best_params': self.best_params,
                'best_score': self.best_score,
                'sample_size': self.sample_size,
                'n_gpus': self.n_gpus,
                'timestamp': time.time(),
                'missing_video_embs': self.missing_video_embs,
                'missing_text_embs': self.missing_text_embs
            }
            with open(output_dir / f"complete_parallel_best_params_mafw.json", 'w') as f:
                json.dump(best_params_info, f, indent=2)
        
        logger.info(f"å®Œæ•´å¹¶è¡Œè°ƒä¼˜ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def run_complete_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å¹¶è¡Œè°ƒä¼˜æµç¨‹"""
        logger.info("å¼€å§‹å®Œæ•´çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜æµç¨‹ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰...")
        
        # åŠ è½½æ•°æ®
        self.load_data()
        
        # è¿è¡Œå¹¶è¡Œç½‘æ ¼æœç´¢
        df_results = self.run_parallel_grid_search()
        
        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        self.create_visualization_plots(df_results)
        
        logger.info(f"å®Œæ•´å¹¶è¡Œè°ƒä¼˜å®Œæˆï¼æœ€ä½³å‚æ•°: {self.best_params}")
        logger.info(f"æœ€ä½³Recall@10: {self.best_score:.4f}")


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´çš„å¤šGPUå¹¶è¡ŒMERLINå‚æ•°è°ƒä¼˜ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰")
    
    # GPUå‚æ•°
    parser.add_argument("--n_gpus", type=int, default=4,
                       help="ä½¿ç”¨çš„GPUæ•°é‡ (é»˜è®¤: 4)")
    parser.add_argument("--sample_size", type=int, default=50,
                       help="éšæœºæŠ½å–çš„æ ·æœ¬æ•°é‡ (é»˜è®¤: 50)")
    
    args = parser.parse_args()
    
    print(f"ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šGPUå¹¶è¡Œ MERLIN å‚æ•°è°ƒä¼˜ï¼ˆçœŸæ­£çš„å¤šè½®äº¤äº’ï¼‰")
    print(f"ğŸ”¢ GPUæ•°é‡: {args.n_gpus}")
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {args.sample_size}")
    print(f"ğŸ’¡ æ¯ä¸ªè§†é¢‘å°†è¿›è¡ŒçœŸæ­£çš„å¤šè½®äº¤äº’ï¼šæé—®â†’è®¡ç®—ç†µâ†’å†³ç­–ask/refineâ†’ç»¼åˆå›ç­”â†’é‡æ’åº")
    print(f"ğŸ“ è§†é¢‘åµŒå…¥ç›®å½•: /home/peterchen/M2/ADEPT/data/mafw/video_embeddings")
    print(f"ğŸ“ æ–‡æœ¬åµŒå…¥ç›®å½•: /home/peterchen/M2/ADEPT/data/mafw/text_embeddings")
    
    try:
        # åˆ›å»ºå®Œæ•´å¹¶è¡Œè°ƒä¼˜å™¨
        complete_tuner = CompleteParallelTuner(
            n_gpus=args.n_gpus,
            sample_size=args.sample_size
        )
        
        # è¿è¡Œå®Œæ•´å¹¶è¡Œè°ƒä¼˜æµç¨‹
        complete_tuner.run_complete_tuning()
        
        print("âœ… å®Œæ•´çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: /home/peterchen/M2/ADEPT/data/mafw/best_parameter/")
        print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†å¹¶è¡Œè°ƒä¼˜è¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œå‚æ•°è°ƒä¼˜å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 