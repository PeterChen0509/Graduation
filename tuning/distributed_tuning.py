#!/usr/bin/env python3
"""
çœŸæ­£çš„åˆ†å¸ƒå¼å‚æ•°è°ƒä¼˜ç³»ç»Ÿ
æ”¯æŒå¤šGPUå¹¶è¡Œå¤„ç†è§†é¢‘å¯¹è¯ï¼Œå¤§å¹…åŠ é€Ÿå‚æ•°è°ƒä¼˜è¿‡ç¨‹
"""

import os
import sys
import json
import time
import random
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import argparse
from tqdm import tqdm
import itertools
import torch
import multiprocessing as mp
from functools import partial

# è‡ªåŠ¨è®¾ç½®PYTHONPATH
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from parameter_tuning import ParameterTuner
from utils.logger import logger, setup_logger

class TrueDistributedParameterTuner:
    """
    çœŸæ­£çš„åˆ†å¸ƒå¼å‚æ•°è°ƒä¼˜å™¨
    æ”¯æŒå¤šGPUå¹¶è¡Œå¤„ç†è§†é¢‘å¯¹è¯ï¼Œæ¯ä¸ªGPUå¤„ç†ä¸€ä¸ªè§†é¢‘
    """
    
    def __init__(self, 
                 dataset: str,
                 data_path: str,
                 excel_path: str = None,
                 video_base_dir: str = None,
                 output_dir: str = "outputs",
                 env_file: str = "/home/peterchen/M2/ADEPT/.env",
                 n_gpus: int = None):
        """
        åˆå§‹åŒ–çœŸæ­£çš„åˆ†å¸ƒå¼å‚æ•°è°ƒä¼˜å™¨
        
        Args:
            n_gpus: ä½¿ç”¨çš„GPUæ•°é‡ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        """
        # è‡ªåŠ¨æ£€æµ‹GPUæ•°é‡
        if n_gpus is None:
            n_gpus = torch.cuda.device_count()
            if n_gpus == 0:
                n_gpus = 1  # å¦‚æœæ²¡æœ‰GPUï¼Œä½¿ç”¨CPU
                logger.warning("æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        
        self.n_gpus = n_gpus
        self.dataset = dataset
        self.data_path = data_path
        self.excel_path = excel_path
        self.video_base_dir = video_base_dir
        self.output_dir = output_dir
        self.env_file = env_file
        
        # ç»“æœå­˜å‚¨
        self.results = []
        self.best_params = None
        self.best_score = 0.0
        
        logger.info(f"çœŸæ­£çš„åˆ†å¸ƒå¼è°ƒä¼˜å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ {n_gpus} ä¸ªGPU")
        logger.info(f"æ¯ä¸ªGPUå°†å¹¶è¡Œå¤„ç†ä¸€ä¸ªè§†é¢‘å¯¹è¯")
    
    def _evaluate_single_video_parallel(self, 
                                      video_idx: int, 
                                      params: Dict[str, Any],
                                      gpu_id: int,
                                      val_queries: List,
                                      val_video_embs: List,
                                      val_text_embs: List,
                                      video_captions: Dict,
                                      dataset_config: Any,
                                      dataset_paths: Any) -> Dict[str, Any]:
        """
        åœ¨æŒ‡å®šGPUä¸Šè¯„ä¼°å•ä¸ªè§†é¢‘
        
        Args:
            video_idx: è§†é¢‘ç´¢å¼•
            params: å‚æ•°å­—å…¸
            gpu_id: GPU ID
            val_queries: éªŒè¯é›†æŸ¥è¯¢
            val_video_embs: éªŒè¯é›†è§†é¢‘åµŒå…¥
            val_text_embs: éªŒè¯é›†æ–‡æœ¬åµŒå…¥
            video_captions: è§†é¢‘æè¿°
            dataset_config: æ•°æ®é›†é…ç½®
            dataset_paths: æ•°æ®é›†è·¯å¾„
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        try:
            # è®¾ç½®GPU
            if torch.cuda.is_available():
                torch.cuda.set_device(gpu_id)
                device = f"cuda:{gpu_id}"
            else:
                device = "cpu"
            
            # åˆ›å»ºç‹¬ç«‹çš„tunerå®ä¾‹ï¼ˆé¿å…GPUå†²çªï¼‰
            tuner = ParameterTuner(
                dataset=self.dataset,
                data_path=self.data_path,
                excel_path=self.excel_path,
                video_base_dir=self.video_base_dir,
                output_dir=self.output_dir,
                env_file=self.env_file
            )
            
            # ä½¿ç”¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
            tuner.val_queries = val_queries
            tuner.val_video_embs = val_video_embs
            tuner.val_text_embs = val_text_embs
            tuner.video_captions = video_captions
            tuner.dataset_config = dataset_config
            tuner.dataset_paths = dataset_paths
            
            # è¯„ä¼°å•ä¸ªè§†é¢‘
            result = tuner._evaluate_single_video(video_idx, params)
            
            logger.info(f"GPU {gpu_id} å®Œæˆè§†é¢‘ {video_idx}: åˆå§‹æ’å={result['initial_rank']}, æœ€ç»ˆæ’å={result['final_rank']}")
            
            return result
            
        except Exception as e:
            logger.error(f"GPU {gpu_id} è¯„ä¼°è§†é¢‘ {video_idx} å¤±è´¥: {str(e)}")
            return {
                'target_vid': f"video_{video_idx}",
                'initial_rank': float('inf'),
                'final_rank': float('inf'),
                'final_round': 0,
                'improvement': 0,
                'error': str(e)
            }
    
    def _evaluate_parameter_combination_parallel(self, params: Dict[str, Any], sample_size: int = 50) -> Dict[str, Any]:
        """
        å¹¶è¡Œè¯„ä¼°å•ä¸ªå‚æ•°ç»„åˆ
        
        Args:
            params: å‚æ•°å­—å…¸
            sample_size: è¯„ä¼°æ ·æœ¬æ•°é‡
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        logger.info(f"å¼€å§‹å¹¶è¡Œè¯„ä¼°å‚æ•°ç»„åˆ: m={params['m']}, Î±={params['alpha']}, Î²={params['beta']}")
        
        # åˆ›å»ºåŸºç¡€tuneræ¥è·å–æ•°æ®
        base_tuner = ParameterTuner(
            dataset=self.dataset,
            data_path=self.data_path,
            excel_path=self.excel_path,
            video_base_dir=self.video_base_dir,
            output_dir=self.output_dir,
            env_file=self.env_file
        )
        
        # ç¡®å®šè¯„ä¼°æ ·æœ¬
        if sample_size is None:
            eval_queries = base_tuner.val_queries
        else:
            eval_queries = base_tuner.val_queries[:sample_size]
        
        logger.info(f"å¹¶è¡Œè¯„ä¼°æ ·æœ¬æ•°é‡: {len(eval_queries)}")
        
        # å‡†å¤‡å…±äº«æ•°æ®
        val_queries = base_tuner.val_queries
        val_video_embs = base_tuner.val_video_embs
        val_text_embs = base_tuner.val_text_embs
        video_captions = base_tuner.video_captions
        dataset_config = base_tuner.dataset_config
        dataset_paths = base_tuner.dataset_paths
        
        # åˆ†é…GPUä»»åŠ¡
        video_indices = list(range(len(eval_queries)))
        gpu_assignments = []
        
        for i, video_idx in enumerate(video_indices):
            gpu_id = i % self.n_gpus
            gpu_assignments.append((video_idx, gpu_id))
        
        logger.info(f"ä»»åŠ¡åˆ†é…: {len(gpu_assignments)} ä¸ªè§†é¢‘åˆ†é…åˆ° {self.n_gpus} ä¸ªGPU")
        
        # å¹¶è¡Œå¤„ç†
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=self.n_gpus) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_video = {}
            for video_idx, gpu_id in gpu_assignments:
                future = executor.submit(
                    self._evaluate_single_video_parallel,
                    video_idx, params, gpu_id,
                    val_queries, val_video_embs, val_text_embs,
                    video_captions, dataset_config, dataset_paths
                )
                future_to_video[future] = video_idx
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(as_completed(future_to_video), 
                             total=len(gpu_assignments), 
                             desc=f"å¹¶è¡Œè¯„ä¼°å‚æ•°ç»„åˆ"):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    video_idx = future_to_video[future]
                    logger.error(f"è§†é¢‘ {video_idx} è¯„ä¼°å¤±è´¥: {str(e)}")
                    results.append({
                        'target_vid': f"video_{video_idx}",
                        'initial_rank': float('inf'),
                        'final_rank': float('inf'),
                        'final_round': 0,
                        'improvement': 0,
                        'error': str(e)
                    })
        
        end_time = time.time()
        parallel_time = end_time - start_time
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        valid_results = [r for r in results if 'error' not in r]
        error_results = [r for r in results if 'error' in r]
        
        logger.info(f"å¹¶è¡Œè¯„ä¼°å®Œæˆ: æˆåŠŸ={len(valid_results)}, å¤±è´¥={len(error_results)}")
        logger.info(f"å¹¶è¡Œè€—æ—¶: {parallel_time:.2f}ç§’")
        
        if not valid_results:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ")
            return {
                'params': params,
                'avg_final_rank': float('inf'),
                'avg_improvement': 0.0,
                'top1_accuracy': 0.0,
                'top5_accuracy': 0.0,
                'top10_accuracy': 0.0,
                'recall_at_10': 0.0,
                'num_samples': 0,
                'parallel_time': parallel_time
            }
        
        # è®¡ç®—æŒ‡æ ‡
        final_ranks = [r['final_rank'] for r in valid_results]
        improvements = [r['improvement'] for r in valid_results]
        
        # è®¡ç®—å‡†ç¡®ç‡
        top1_count = sum(1 for rank in final_ranks if rank == 1)
        top5_count = sum(1 for rank in final_ranks if rank <= 5)
        top10_count = sum(1 for rank in final_ranks if rank <= 10)
        
        # è®¡ç®—Recall@10
        recall_at_10 = top10_count / len(valid_results)
        
        avg_final_rank = np.mean(final_ranks)
        avg_improvement = np.mean(improvements)
        top1_accuracy = top1_count / len(valid_results)
        top5_accuracy = top5_count / len(valid_results)
        top10_accuracy = top10_count / len(valid_results)
        
        logger.info(f"å‚æ•°ç»„åˆå¹¶è¡Œè¯„ä¼°å®Œæˆ: Recall@10={recall_at_10:.4f}, Top1={top1_accuracy:.4f}")
        
        return {
            'params': params,
            'avg_final_rank': avg_final_rank,
            'avg_improvement': avg_improvement,
            'top1_accuracy': top1_accuracy,
            'top5_accuracy': top5_accuracy,
            'top10_accuracy': top10_accuracy,
            'recall_at_10': recall_at_10,
            'num_samples': len(valid_results),
            'detailed_results': valid_results,
            'parallel_time': parallel_time
        }
    
    def run_parallel_grid_search(self, save_results: bool = True) -> pd.DataFrame:
        """
        è¿è¡Œå¹¶è¡Œç½‘æ ¼æœç´¢
        
        Args:
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            ç»“æœDataFrame
        """
        logger.info("å¼€å§‹çœŸæ­£çš„å¹¶è¡Œç½‘æ ¼æœç´¢...")
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_space = {
            'm': [5, 8, 10, 12],  # K-meansç°‡æ•°
            'alpha': [0.3, 0.5, 0.7],  # ç°‡é—´ç†µé˜ˆå€¼
            'beta': [0.2, 0.4, 0.6]   # ç°‡å†…ç†µé˜ˆå€¼
        }
        
        param_combinations = list(itertools.product(
            param_space['m'],
            param_space['alpha'],
            param_space['beta']
        ))
        
        logger.info(f"æ€»å…± {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆéœ€è¦è¯„ä¼°")
        logger.info(f"ä½¿ç”¨ {self.n_gpus} ä¸ªGPUå¹¶è¡Œå¤„ç†")
        
        # ä¼°ç®—æ—¶é—´
        estimated_time_per_combination = 2 * 50 / self.n_gpus / 60  # åˆ†é’Ÿ
        total_estimated_time = len(param_combinations) * estimated_time_per_combination
        logger.info(f"é¢„è®¡æ€»æ—¶é—´: {total_estimated_time:.1f} åˆ†é’Ÿ ({total_estimated_time/60:.1f} å°æ—¶)")
        
        # ä¸²è¡Œè¯„ä¼°å‚æ•°ç»„åˆï¼ˆä½†æ¯ä¸ªç»„åˆå†…éƒ¨å¹¶è¡Œï¼‰
        start_time = time.time()
        results = []
        
        for m, alpha, beta in tqdm(param_combinations, desc="å‚æ•°ç»„åˆè¿›åº¦"):
            params = {'m': m, 'alpha': alpha, 'beta': beta}
            
            try:
                result = self._evaluate_parameter_combination_parallel(params, sample_size=50)
                results.append(result)
                
                # æ›´æ–°æœ€ä½³å‚æ•°
                if result['recall_at_10'] > self.best_score:
                    self.best_score = result['recall_at_10']
                    self.best_params = params
                    logger.info(f"å‘ç°æ–°çš„æœ€ä½³å‚æ•°: {params}, Recall@10={self.best_score:.4f}")
                
            except Exception as e:
                logger.error(f"è¯„ä¼°å‚æ•°ç»„åˆå¤±è´¥: {params}, é”™è¯¯: {str(e)}")
                continue
        
        end_time = time.time()
        actual_time = (end_time - start_time) / 60  # åˆ†é’Ÿ
        logger.info(f"å®é™…è€—æ—¶: {actual_time:.1f} åˆ†é’Ÿ")
        if total_estimated_time > 0:
            logger.info(f"åŠ é€Ÿæ¯”: {total_estimated_time/actual_time:.1f}x")
        
        # è½¬æ¢ä¸ºDataFrame
        df_results = []
        for result in results:
            df_results.append({
                'm': result['params']['m'],
                'alpha': result['params']['alpha'],
                'beta': result['params']['beta'],
                'recall_at_10': result['recall_at_10'],
                'top1_accuracy': result['top1_accuracy'],
                'top5_accuracy': result['top5_accuracy'],
                'top10_accuracy': result['top10_accuracy'],
                'avg_final_rank': result['avg_final_rank'],
                'avg_improvement': result['avg_improvement'],
                'num_samples': result['num_samples'],
                'parallel_time': result.get('parallel_time', 0)
            })
        
        self.results = results
        df = pd.DataFrame(df_results)
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self._save_parallel_results(df)
        
        return df
    
    def _save_parallel_results(self, df: pd.DataFrame):
        """ä¿å­˜å¹¶è¡Œè°ƒä¼˜ç»“æœ"""
        output_dir = Path("/home/peterchen/M2/ADEPT/data/mafw/best_parameter")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜DataFrame
        df.to_csv(output_dir / f"parallel_grid_search_results_{self.dataset}.csv", index=False)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open(output_dir / f"parallel_detailed_results_{self.dataset}.json", 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        if self.best_params:
            best_params_info = {
                'best_params': self.best_params,
                'best_score': self.best_score,
                'dataset': self.dataset,
                'timestamp': time.time(),
                'n_gpus': self.n_gpus,
                'total_combinations': len(self.results)
            }
            with open(output_dir / f"parallel_best_params_{self.dataset}.json", 'w') as f:
                json.dump(best_params_info, f, indent=2)
        
        logger.info(f"å¹¶è¡Œè°ƒä¼˜ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def run_complete_parallel_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å¹¶è¡Œè°ƒä¼˜æµç¨‹"""
        logger.info("å¼€å§‹å®Œæ•´çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜æµç¨‹...")
        
        # è¿è¡Œå¹¶è¡Œç½‘æ ¼æœç´¢
        df_results = self.run_parallel_grid_search(save_results=True)
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³å‚æ•°
        if self.best_params:
            logger.info(f"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³å‚æ•°: {self.best_params}")
            
            # åˆ›å»ºåŸºç¡€tunerè¿›è¡Œæµ‹è¯•é›†è¯„ä¼°
            base_tuner = ParameterTuner(
                dataset=self.dataset,
                data_path=self.data_path,
                excel_path=self.excel_path,
                video_base_dir=self.video_base_dir,
                output_dir=self.output_dir,
                env_file=self.env_file
            )
            
            test_result = base_tuner.evaluate_best_params_on_test_set()
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            output_dir = Path("/home/peterchen/M2/ADEPT/data/mafw/best_parameter")
            test_result_info = {
                'best_params': self.best_params,
                'test_results': test_result,
                'dataset': self.dataset,
                'timestamp': time.time(),
                'n_gpus': self.n_gpus
            }
            
            with open(output_dir / f"parallel_test_evaluation_{self.dataset}.json", 'w') as f:
                json.dump(test_result_info, f, indent=2, default=str)
            
            logger.info(f"å¹¶è¡Œè°ƒä¼˜å®Œæˆï¼æœ€ä½³å‚æ•°: {self.best_params}")
            logger.info(f"æµ‹è¯•é›†Recall@10: {test_result.get('recall_at_10', 0):.4f}")
        else:
            logger.error("æ²¡æœ‰æ‰¾åˆ°æœ€ä½³å‚æ•°")

# ä¿æŒå‘åå…¼å®¹æ€§
class DistributedParameterTuner(TrueDistributedParameterTuner):
    """å‘åå…¼å®¹çš„åˆ†å¸ƒå¼å‚æ•°è°ƒä¼˜å™¨"""
    pass

def main():
    parser = argparse.ArgumentParser(description="çœŸæ­£çš„å¤šGPUå¹¶è¡ŒMERLINå‚æ•°è°ƒä¼˜")
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--dataset", type=str, choices=["mafw"], default="mafw", 
                       help="æ•°æ®é›†åç§°")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--data_path", type=str, default="data", 
                       help="æ•°æ®è·¯å¾„")
    parser.add_argument("--excel_path", type=str, 
                       default="/home/peterchen/M2/ADEPT/data/mafw/labels/sampled_850.xlsx",
                       help="Excelæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--video_base_dir", type=str,
                       default="/home/peterchen/M2/MAFW/data/clips/unzip",
                       help="è§†é¢‘åŸºç¡€ç›®å½•")
    parser.add_argument("--output_dir", type=str, default="outputs", 
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--env_file", type=str, 
                       default="/home/peterchen/M2/ADEPT/.env",
                       help="ç¯å¢ƒå˜é‡æ–‡ä»¶è·¯å¾„")
    
    # GPUå‚æ•°
    parser.add_argument("--n_gpus", type=int, default=None,
                       help="ä½¿ç”¨çš„GPUæ•°é‡ (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)")
    
    args = parser.parse_args()
    
    print(f"ğŸš€ å¼€å§‹çœŸæ­£çš„å¤šGPUå¹¶è¡Œ MERLIN å‚æ•°è°ƒä¼˜")
    print(f"ğŸ“Š æ•°æ®é›†: {args.dataset}")
    print(f"ğŸ”¢ GPUæ•°é‡: {args.n_gpus or 'è‡ªåŠ¨æ£€æµ‹'}")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {args.data_path}")
    print(f"ğŸ“Š Excelæ–‡ä»¶: {args.excel_path}")
    print(f"ğŸ¬ è§†é¢‘ç›®å½•: {args.video_base_dir}")
    
    try:
        # åˆ›å»ºçœŸæ­£çš„åˆ†å¸ƒå¼è°ƒä¼˜å™¨
        parallel_tuner = TrueDistributedParameterTuner(
            dataset=args.dataset,
            data_path=args.data_path,
            excel_path=args.excel_path,
            video_base_dir=args.video_base_dir,
            output_dir=args.output_dir,
            env_file=args.env_file,
            n_gpus=args.n_gpus
        )
        
        # è¿è¡Œå®Œæ•´å¹¶è¡Œè°ƒä¼˜æµç¨‹
        parallel_tuner.run_complete_parallel_tuning()
        
        print("âœ… çœŸæ­£çš„å¹¶è¡Œå‚æ•°è°ƒä¼˜å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: /home/peterchen/M2/ADEPT/data/mafw/best_parameter/")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†å¹¶è¡Œè°ƒä¼˜è¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ å¹¶è¡Œå‚æ•°è°ƒä¼˜å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 