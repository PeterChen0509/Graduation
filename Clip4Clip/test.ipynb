{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6253ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab6b8ba22864fbb9a67bca95cfa3b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7e631012f64ff2a4407fafb4a311e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48114bf0c444c22a4beaf715b40d88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5714ffbb4648e49e9b73a917b2e746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5788da1f6af4445aa9ca6d339a482eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca5959a13c44581aa23d12ff7ffb49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6135c3bf13a64d96937b269821230911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output:  [[ 3.25408089e-03  3.06101162e-02 -4.06834446e-02  4.61272057e-03\n",
      "  -1.57766044e-02  5.83211333e-02  4.99447668e-03  4.67521586e-02\n",
      "  -4.83069420e-02  3.04725897e-02  1.57634560e-02 -2.27446780e-02\n",
      "   1.32764336e-02 -3.03331427e-02  1.68683343e-02  5.01386039e-02\n",
      "   2.19177678e-02  5.90111539e-02 -8.10485408e-02  5.94285317e-03\n",
      "   3.03250942e-02 -1.44688124e-02 -4.80068661e-02  3.04664560e-02\n",
      "  -2.16435455e-02 -3.31622921e-02  3.50620486e-02  2.53910311e-02\n",
      "  -2.58109812e-02  2.34463289e-02  5.43020386e-03 -2.20337007e-02\n",
      "   2.19517220e-02  1.27743213e-02 -5.26760751e-03 -6.62063994e-03\n",
      "   1.27831725e-02 -1.72309522e-02 -3.70556079e-02 -7.25613255e-03\n",
      "  -1.30738167e-03  2.93124877e-02 -3.73392254e-02  2.49769026e-03\n",
      "   7.39447959e-03  6.05660118e-02 -1.62404310e-02 -3.56167257e-02\n",
      "  -6.44444153e-02 -2.67125443e-02  6.91965371e-02 -4.47211899e-02\n",
      "  -6.60525411e-02 -2.99654398e-02 -1.50894548e-03 -1.45027079e-02\n",
      "  -1.23195080e-02 -1.07174404e-02  6.69275550e-03 -1.29440846e-02\n",
      "   7.52260908e-02 -5.01072742e-02 -3.98161113e-02 -2.05196403e-02\n",
      "  -2.33834255e-02 -4.13309522e-02  2.24572103e-02  1.20407850e-01\n",
      "  -2.38472852e-03 -4.94373217e-02 -2.64670886e-02 -4.45479155e-02\n",
      "   9.33892746e-03  3.94949690e-02 -6.11238964e-02  1.73258670e-02\n",
      "  -5.60525339e-03  7.31558949e-02  1.73109174e-02 -5.44079114e-03\n",
      "  -4.52553928e-02  1.47372419e-02 -5.01131378e-02  6.53152689e-02\n",
      "  -4.25786562e-02 -3.87025774e-02 -6.11097887e-02 -5.58273401e-03\n",
      "  -4.47172448e-02 -1.88573860e-02 -4.11944091e-02  3.67935561e-02\n",
      "  -6.63750097e-02  1.48474146e-02  1.37935122e-02  2.32521277e-02\n",
      "  -2.85270009e-02 -8.70349854e-02  6.28940295e-03 -5.68202734e-02\n",
      "   3.61009762e-02  4.57103550e-03  7.51724914e-02 -5.54127013e-03\n",
      "  -2.29939097e-03 -2.83194166e-02 -2.98186168e-02 -3.66047621e-02\n",
      "   8.53324216e-03 -2.07777712e-02 -6.54346719e-02 -2.84576714e-02\n",
      "  -1.61352158e-02 -3.20651233e-02 -2.66220253e-02  1.37290563e-02\n",
      "  -3.15599218e-02  3.28243077e-02  3.04638650e-02  1.29429689e-02\n",
      "   2.27544568e-02  4.96679498e-03  2.10530013e-02 -3.15765366e-02\n",
      "   2.86835566e-04 -4.35953662e-02 -4.15090583e-02 -3.14125121e-02\n",
      "   3.84772532e-02  3.06945387e-02  6.22227117e-02 -2.74288524e-02\n",
      "  -9.44378041e-03  3.82188201e-01 -5.37333786e-02 -7.65434280e-02\n",
      "  -1.41261201e-02 -6.97561204e-02  1.79773942e-02  3.87560157e-03\n",
      "  -8.48847628e-03 -7.07675517e-02  9.61814891e-04  2.10121572e-02\n",
      "   3.05180419e-02  1.45912133e-02  9.17615369e-03  5.38904592e-02\n",
      "  -2.93095503e-02  1.30669437e-02 -2.41474044e-02  2.01382469e-02\n",
      "   4.64681117e-03  4.24186047e-03  1.54759744e-02  2.75960565e-02\n",
      "   4.82550152e-02  7.44067831e-03  1.17363073e-02 -2.30362620e-02\n",
      "  -3.36220637e-02 -3.54527459e-02 -2.89712171e-03  2.12796070e-02\n",
      "  -1.95595752e-02  1.49319805e-02  1.08283851e-02  4.21692571e-03\n",
      "   4.43096459e-02  3.03142518e-02  3.04817222e-02 -1.43521093e-02\n",
      "  -3.65676954e-02  2.04406362e-02 -1.66586917e-02  1.51686380e-02\n",
      "   8.42386205e-03 -6.49644015e-03 -4.26440686e-02 -4.51753400e-02\n",
      "   4.00974154e-02 -2.82293260e-02 -1.30386688e-02  2.13373061e-02\n",
      "  -5.95168360e-02 -6.21859916e-02  6.39375150e-02 -2.64901388e-03\n",
      "  -6.43001720e-02  5.91845214e-02 -2.17003701e-03  9.49772745e-02\n",
      "  -1.43399658e-02  1.34000797e-02  1.03149023e-02  1.96511056e-02\n",
      "   1.10916896e-02  7.56347999e-02 -5.38333610e-04  2.99952459e-02\n",
      "  -2.38110181e-02 -6.29505841e-03  1.77477933e-02  1.90311903e-03\n",
      "  -3.57068442e-02 -1.20594846e-02  1.36635285e-02 -5.37626818e-02\n",
      "  -2.59748325e-02  6.20974088e-03  7.99404830e-02  2.02757996e-02\n",
      "  -4.10547145e-02  5.62058911e-02  1.26788849e-02 -2.35079154e-02\n",
      "   2.13875659e-02 -1.06875468e-02  4.66731228e-02  8.37722793e-03\n",
      "   2.70783920e-02  4.41051498e-02  2.25223769e-02 -3.30872051e-02\n",
      "   1.87247247e-02  1.50888031e-02 -4.13727835e-02 -2.15089489e-02\n",
      "   3.05292243e-03 -3.27824466e-02 -9.70039051e-03  8.34541302e-03\n",
      "  -1.06780194e-02 -3.49234566e-02  3.85937244e-02  9.22611170e-03\n",
      "  -1.32314749e-02 -3.54965404e-02 -6.96909577e-02 -5.75284697e-02\n",
      "   9.41685066e-02 -1.53022502e-02 -8.11429247e-02 -2.05290634e-02\n",
      "  -6.52778074e-02  3.01247439e-03  1.04805371e-02  4.72677387e-02\n",
      "   1.04472088e-02 -2.28035115e-02 -5.59131056e-02  3.29828486e-02\n",
      "  -6.19818270e-02  3.51080522e-02  3.28814052e-02  4.16246317e-02\n",
      "  -2.77222674e-02  7.91249331e-04 -5.00349049e-03  5.18868640e-02\n",
      "  -6.89370632e-02 -1.29155396e-02 -2.76650265e-02 -3.86719666e-02\n",
      "  -2.90705562e-02 -6.79892953e-03  2.99895164e-02 -2.72631515e-02\n",
      "   2.91980407e-03 -6.60180897e-02 -2.64498889e-02 -1.16499839e-02\n",
      "   2.36161444e-02 -3.15835364e-02 -4.52976003e-02 -4.88089994e-02\n",
      "  -6.64856704e-03 -4.58840765e-02  7.00275823e-02  1.74273085e-02\n",
      "   1.60576068e-02  6.58416748e-02  1.01634478e-02 -5.51125072e-02\n",
      "   1.88104343e-02  3.74434292e-02  1.91553589e-02 -5.45821013e-03\n",
      "   3.26237418e-02 -2.45305076e-02  5.58460057e-02  5.18924138e-03\n",
      "  -6.26613647e-02  5.97318634e-02  3.70631069e-02  3.43028083e-02\n",
      "  -3.34315151e-02  2.31232215e-02 -4.27638590e-02 -1.23644825e-02\n",
      "  -3.52047995e-04 -1.49528161e-02 -3.88155021e-02  5.14082946e-02\n",
      "  -2.96202339e-02 -1.46241307e-01  9.55106970e-03  4.98433423e-04\n",
      "   1.47740077e-02 -1.48090869e-02 -3.69480666e-04  2.37108935e-02\n",
      "   3.82357806e-01  9.95389372e-03  2.35677529e-02  2.06914209e-02\n",
      "   5.08024022e-02 -1.14651777e-01 -1.43073231e-03 -2.55759545e-02\n",
      "   2.29230430e-02 -2.02849135e-02 -1.16136624e-03  2.53188349e-02\n",
      "  -7.02993795e-02 -4.37120460e-02 -2.57955026e-02 -1.79441050e-02\n",
      "  -5.25558107e-02  6.12191521e-02 -2.77698096e-02 -2.25413255e-02\n",
      "  -3.74867059e-02 -5.08741103e-02 -3.58528495e-02 -1.19903209e-02\n",
      "  -3.34056169e-02  1.86970904e-02  4.88425791e-02 -2.92761307e-02\n",
      "   1.19582750e-02  5.39850025e-03  3.55787501e-02  7.14775845e-02\n",
      "   2.83574536e-02 -4.52920645e-02  3.99527065e-02  5.14985062e-02\n",
      "  -7.95156788e-03  4.02740501e-02  2.59512886e-02  1.14643620e-02\n",
      "  -2.50497255e-02 -2.78137531e-03 -1.25807701e-02 -8.94097537e-02\n",
      "  -2.35395762e-03  2.52838209e-02  2.12913677e-02  3.20554189e-02\n",
      "  -5.22344653e-03 -5.94762862e-02  4.72520106e-02 -2.74706129e-02\n",
      "   5.21634035e-02 -4.09203209e-03 -1.69661641e-02  2.46796161e-02\n",
      "  -1.66236646e-02  4.76316623e-02 -2.17981543e-02  4.19829339e-02\n",
      "   4.63931635e-03  4.58439291e-02 -1.10567557e-02  3.39383148e-02\n",
      "  -1.81228071e-02  2.35276744e-02 -2.72727222e-03 -5.63802160e-02\n",
      "  -5.74994087e-02 -5.90361916e-02 -5.91888977e-03 -6.08632751e-02\n",
      "  -4.15260568e-02 -1.82340126e-02 -6.25411123e-02 -1.72709674e-02\n",
      "  -3.57633308e-02  2.17835493e-02 -4.40497994e-02  4.26961556e-02\n",
      "  -4.23944928e-02  6.27956092e-02  5.53266965e-02 -2.50705518e-02\n",
      "   1.30335525e-01 -3.73002631e-03  1.64415855e-02  2.33298470e-03\n",
      "   8.51969793e-03 -4.74374145e-02  3.10657546e-02  2.75511369e-02\n",
      "  -4.83653061e-02  2.38461290e-02  1.58563443e-02 -2.57406216e-02\n",
      "   1.74089484e-02  3.92374620e-02  7.15850666e-02  2.12355405e-02\n",
      "   3.62850502e-02  1.97885726e-02 -6.51338929e-03  5.56143979e-03\n",
      "  -1.90571863e-02  3.64698134e-02 -1.25591215e-02  2.01648138e-02\n",
      "   2.79116109e-02 -1.08379228e-02 -1.94931291e-02 -2.05199909e-03\n",
      "  -5.32370899e-03 -8.47016945e-02  1.36641343e-03 -3.78191285e-02\n",
      "  -9.32937081e-04 -4.19117473e-02 -3.31550241e-02  6.55370532e-03\n",
      "   2.61458885e-02 -6.00670576e-02 -5.32171689e-02 -3.72732454e-03\n",
      "  -5.96730039e-02  6.44962266e-02  1.55693470e-02 -6.57883473e-03\n",
      "   5.44965873e-03 -1.67710576e-02 -2.98811011e-02 -4.78500297e-04\n",
      "   2.35671774e-02 -4.32525612e-02 -4.14471477e-02 -1.43511035e-02\n",
      "  -7.89153874e-02  4.70088935e-03  2.25639381e-02  5.42173674e-03\n",
      "  -8.67705233e-03  3.38743962e-02 -5.30332047e-03  8.74696113e-03\n",
      "  -8.39338929e-04 -2.25483365e-02  2.14721747e-02 -3.32800634e-02\n",
      "  -9.60733090e-03  4.55220975e-03 -5.12505136e-03 -1.95682216e-02\n",
      "  -8.78585037e-03 -3.19898576e-02 -2.14853082e-02  5.40318228e-02\n",
      "  -1.23554049e-02 -9.68034752e-03 -7.88672119e-02  3.12130488e-02\n",
      "   4.55199853e-02 -6.83084428e-02 -2.74733286e-02 -1.64227225e-02\n",
      "   1.66822113e-02  1.13536716e-02 -3.19869369e-02  6.70894189e-03\n",
      "   4.05701175e-02 -8.84772651e-03  1.65196005e-02  3.72100919e-02\n",
      "  -4.94335331e-02  1.04327276e-02  6.73431754e-02  1.55770192e-02\n",
      "   1.61271282e-02 -1.59045924e-02  2.60482449e-03 -8.54110112e-04\n",
      "  -1.67779643e-02  1.31692052e-01 -2.20342143e-03 -3.62702273e-02\n",
      "  -2.81886104e-02 -2.79184282e-02 -4.51458208e-02 -9.77065880e-03\n",
      "  -1.24021014e-02 -8.73075891e-03  2.06314903e-02  4.99025844e-02\n",
      "   2.64817029e-02 -6.60288008e-03  1.38285682e-02 -1.04896203e-02\n",
      "   7.71801127e-03  7.92070031e-02 -5.69811463e-02 -5.09474128e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Text Embedding\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "search_sentence = \"a basketball player performing a slam dunk\"\n",
    "\n",
    "model = CLIPTextModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
    "\n",
    "inputs = tokenizer(text=search_sentence, return_tensors=\"pt\")\n",
    "outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "final_output = outputs[0] / outputs[0].norm(dim=-1, keepdim=True)\n",
    "final_output = final_output.cpu().detach().numpy()\n",
    "print(\"final output: \", final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ffc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"/home/peterchen/M2/ADEPT/data/mafw/videos/00095.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b503cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Embedding\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, InterpolationMode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def video2image(video_path, frame_rate=1.0, size=224):\n",
    "    def preprocess(size, n_px):\n",
    "        return Compose([\n",
    "            Resize(size, interpolation=InterpolationMode.BICUBIC),\n",
    "            CenterCrop(size),\n",
    "            lambda image: image.convert(\"RGB\"),\n",
    "            ToTensor(),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])(n_px)\n",
    "        \n",
    "    # cap = cv2.VideoCapture(video_path)\n",
    "    cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    if fps < 1:\n",
    "        images = np.zeros([3, size, size], dtype=np.float32)\n",
    "        print(\"ERROR: problem reading video file: \", video_path)\n",
    "    else:\n",
    "        total_duration = (frameCount + fps - 1) // fps\n",
    "        start_sec, end_sec = 0, total_duration\n",
    "        interval = fps / frame_rate\n",
    "        frame_idx = np.floor(np.arange(start_sec*fps, end_sec*fps, interval))\n",
    "        ret = True\n",
    "        images = np.zeros([len(frame_idx), 3, size, size], dtype=np.float32)\n",
    "        \n",
    "        for i, idx in enumerate(frame_idx):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            last_frame = i\n",
    "            images[i, :, :, :] = preprocess(size, Image.fromarray(frame).convert(\"RGB\"))\n",
    "        \n",
    "        images = images[:last_frame+1]\n",
    "    cap.release()\n",
    "    video_frames = torch.tensor(images)\n",
    "    return video_frames\n",
    "\n",
    "video = video2image(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fd6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5028e-02, -3.5851e-02,  2.0197e-02, -2.0736e-02,  1.1188e-02,\n",
      "         3.5648e-03,  6.8261e-03,  1.7236e-02, -5.6622e-02, -5.7398e-04,\n",
      "         9.0653e-03,  3.3710e-02,  1.0795e-05,  1.4801e-02, -4.7317e-03,\n",
      "        -1.8515e-02,  1.3165e-01, -3.6842e-02,  1.0471e-02, -1.5633e-02,\n",
      "        -3.1747e-02, -9.7641e-03,  1.9203e-03,  1.7060e-03,  8.7066e-03,\n",
      "         4.7712e-02, -1.0660e-02,  6.0551e-02,  2.0917e-02,  5.5179e-02,\n",
      "        -2.1516e-02,  1.4854e-02, -5.7033e-02, -4.0912e-03, -4.8680e-02,\n",
      "         2.6758e-03,  2.1659e-02, -1.6136e-02, -7.9793e-02,  7.6145e-02,\n",
      "         5.4530e-03, -9.7047e-03, -1.1157e-02, -6.5071e-03, -4.6192e-02,\n",
      "         9.9330e-02, -1.6618e-02,  3.8322e-02, -5.2666e-02, -1.2135e-02,\n",
      "         1.3920e-02,  1.5180e-02, -3.5461e-02, -4.8166e-02, -4.5606e-02,\n",
      "         3.5957e-02,  9.4075e-02,  1.9590e-02, -2.8555e-02,  1.3412e-02,\n",
      "         4.1181e-02,  2.6066e-02, -1.0876e-02, -1.2972e-02, -2.0145e-02,\n",
      "         5.2725e-03,  4.3454e-02, -2.1884e-02, -3.8854e-02, -3.9969e-02,\n",
      "        -1.6552e-03,  8.4557e-03,  1.0777e-02,  4.2402e-02, -2.2152e-03,\n",
      "        -9.8118e-03, -9.8014e-02,  1.0639e-02, -2.5012e-03, -2.4660e-02,\n",
      "        -3.8882e-02, -1.3057e-03,  4.3580e-02, -3.3402e-02,  2.2000e-02,\n",
      "        -2.9344e-02,  3.4398e-02, -2.3126e-02,  2.0326e-03,  6.8058e-03,\n",
      "        -1.3169e-03, -9.9505e-03, -4.9235e-01, -8.1283e-02, -1.6180e-02,\n",
      "         1.2395e-02, -3.0519e-02, -2.2426e-02,  1.3055e-01,  6.6109e-02,\n",
      "        -9.0316e-03, -1.6358e-02, -3.2886e-02,  2.1439e-02, -3.8116e-02,\n",
      "        -8.4446e-02, -8.5220e-02,  8.3222e-03, -3.4482e-02, -1.8277e-02,\n",
      "         7.0653e-02, -9.4837e-02,  5.8234e-03,  2.8892e-03,  2.1984e-02,\n",
      "        -7.9411e-02, -2.7862e-02,  8.8493e-03,  5.6500e-02, -6.0648e-02,\n",
      "        -1.2570e-02,  7.0906e-02,  3.7456e-02, -1.5055e-02, -1.9463e-02,\n",
      "         1.1503e-02, -1.1928e-02, -5.1900e-02, -4.9976e-03, -3.6737e-02,\n",
      "         3.1562e-02,  1.3726e-02,  1.3593e-02,  8.8219e-02,  3.4124e-02,\n",
      "         9.2946e-03,  2.3927e-02,  8.3369e-02, -3.4119e-02, -1.0326e-02,\n",
      "        -3.6867e-02, -2.7653e-03, -1.3051e-02, -2.8528e-02, -2.4605e-02,\n",
      "        -5.4613e-02,  1.6445e-02, -8.0287e-03,  3.4114e-02, -4.8746e-02,\n",
      "        -5.3366e-02, -1.8630e-02,  1.3241e-01, -7.2389e-02,  1.1309e-02,\n",
      "         1.0108e-03,  1.3810e-02, -4.9228e-02,  2.5613e-04,  3.0014e-03,\n",
      "        -3.0191e-02, -7.4779e-02,  2.1094e-03, -1.7198e-02,  3.4494e-02,\n",
      "        -6.8312e-02, -2.8842e-02,  1.9510e-02,  2.2556e-02,  5.0386e-03,\n",
      "        -4.1861e-02, -5.0677e-03, -5.6516e-02, -9.3397e-03,  1.6720e-02,\n",
      "         2.9090e-02,  3.9814e-02, -1.9381e-02, -3.6707e-02,  2.1038e-02,\n",
      "        -4.3611e-04, -1.8996e-03,  5.2161e-02,  2.3997e-02, -3.0025e-02,\n",
      "         3.5233e-02, -4.8573e-02,  3.5321e-02, -1.5316e-02,  1.8012e-02,\n",
      "        -1.3726e-02,  1.2208e-03,  6.9301e-02,  2.6488e-02,  8.0251e-02,\n",
      "         3.6778e-03, -1.3370e-03,  8.6320e-03, -4.0455e-03,  2.8142e-02,\n",
      "         4.5539e-03, -2.4936e-02,  3.5188e-02,  8.5310e-02, -3.3083e-02,\n",
      "         4.4189e-03,  8.2879e-02,  9.5090e-03,  1.6318e-02,  1.4535e-02,\n",
      "        -2.2056e-03, -2.7625e-02,  1.7929e-02,  4.8345e-02, -4.8051e-03,\n",
      "         4.7636e-02, -1.6882e-02,  3.4347e-03, -5.0959e-02, -7.1736e-02,\n",
      "         7.1752e-03,  1.7521e-02,  5.7698e-02,  2.5829e-02, -2.6536e-02,\n",
      "         6.2970e-03,  7.1725e-02, -8.8446e-03, -1.9721e-02,  2.8288e-02,\n",
      "        -1.9375e-02, -1.8924e-02, -3.5693e-04,  2.5895e-03,  7.0194e-04,\n",
      "         6.8729e-03,  4.5342e-02, -1.6207e-02, -1.3900e-02, -1.0834e-02,\n",
      "         2.3435e-02,  9.3302e-03, -3.4500e-02, -1.1228e-02, -2.3070e-02,\n",
      "         6.7414e-02,  3.1945e-02, -3.6722e-02, -2.1470e-02, -2.1011e-03,\n",
      "        -1.0936e-02, -4.5778e-02, -2.4232e-02, -4.4930e-02, -1.1805e-02,\n",
      "        -2.6002e-04,  1.0174e-03, -5.3791e-04, -2.1980e-01, -3.4782e-02,\n",
      "         5.4763e-03,  2.4811e-02,  1.2172e-02, -7.5254e-02, -1.5216e-03,\n",
      "         6.5517e-03, -3.1253e-02,  1.0208e-02,  2.9538e-02,  7.9104e-03,\n",
      "         3.0837e-02,  1.5175e-02, -2.2445e-02,  4.0550e-03, -1.7838e-02,\n",
      "        -8.7761e-03, -1.5500e-02,  5.3511e-02, -6.0802e-02,  2.2879e-02,\n",
      "         2.9245e-02,  1.2163e-02, -9.4103e-03,  2.4880e-02,  5.2421e-03,\n",
      "         2.8689e-02, -6.6203e-02,  1.1711e-02, -8.4580e-03,  7.4446e-03,\n",
      "        -3.1424e-02, -4.2701e-02, -1.8046e-03, -2.6021e-03, -3.7342e-02,\n",
      "         1.9173e-03, -3.3487e-02, -8.3076e-02,  3.0289e-03,  4.8179e-02,\n",
      "        -3.1242e-02, -8.7332e-03, -7.2779e-03, -3.5281e-03,  3.3522e-02,\n",
      "        -2.1411e-02, -5.1079e-03, -1.2869e-05,  3.4471e-02,  5.2679e-02,\n",
      "        -1.6521e-02, -2.8665e-02,  8.7912e-02,  3.3853e-02, -8.7545e-03,\n",
      "         5.6314e-02,  1.8032e-02, -4.4714e-02, -3.0812e-02, -8.3454e-02,\n",
      "        -3.3449e-02, -1.2662e-02,  4.8138e-03,  2.4697e-02,  3.2326e-02,\n",
      "         2.0680e-03,  4.4795e-02, -4.7804e-02,  5.0604e-03, -8.4741e-02,\n",
      "        -1.5896e-03,  5.9998e-03, -1.8760e-02, -1.2480e-02,  3.4020e-02,\n",
      "         9.2862e-06, -1.0236e-02,  5.2265e-02, -2.1168e-02,  2.0332e-02,\n",
      "        -4.5513e-02, -1.3456e-02,  1.1426e-02,  3.6678e-02,  7.4975e-03,\n",
      "        -1.1899e-02, -3.7807e-02,  2.2984e-02,  1.9679e-02,  3.7114e-02,\n",
      "        -1.2037e-02, -6.7416e-03,  2.0177e-02, -2.7699e-02, -2.6144e-02,\n",
      "        -1.1547e-02,  3.1437e-02, -1.3681e-01,  1.1089e-02, -3.3689e-02,\n",
      "        -1.2892e-02,  1.2480e-02,  1.3878e-02,  5.4700e-02,  7.9910e-03,\n",
      "         2.7205e-02, -2.6969e-02, -3.0286e-02, -7.8525e-03,  5.4357e-03,\n",
      "        -2.3810e-02, -2.8261e-02, -1.8889e-03,  6.4672e-02, -9.5598e-02,\n",
      "         4.2685e-03,  3.5435e-02,  1.5752e-02, -8.0301e-02,  3.4072e-02,\n",
      "        -5.8568e-02, -1.8702e-02, -2.4523e-02,  3.4523e-02, -3.7841e-03,\n",
      "         2.2375e-02,  5.0091e-03,  6.2817e-02, -4.8514e-02,  1.0381e-01,\n",
      "        -3.0505e-02, -5.5279e-02, -3.4279e-02, -3.2224e-02, -8.3483e-02,\n",
      "         1.1266e-02,  3.6584e-02,  8.9378e-06,  9.0947e-03, -5.0770e-02,\n",
      "         1.0157e-02,  2.6432e-02, -7.1547e-02, -3.1308e-02,  2.9755e-03,\n",
      "         5.5472e-02, -3.3496e-02,  7.2576e-03, -9.0063e-03,  1.1613e-02,\n",
      "        -5.9541e-02, -1.9037e-02, -3.3766e-02,  1.8069e-02, -9.5420e-03,\n",
      "        -2.2004e-02, -9.3668e-03,  5.5913e-02, -7.7691e-03,  3.8985e-02,\n",
      "        -4.6962e-02, -1.3662e-02, -4.3866e-03, -2.2307e-03, -2.1818e-03,\n",
      "        -5.6251e-03,  1.1306e-02,  2.4065e-02,  1.2388e-01, -1.3931e-03,\n",
      "         4.9345e-02,  1.3062e-02, -1.6303e-01,  2.3992e-02, -5.3240e-03,\n",
      "        -1.1103e-02, -5.8153e-04, -3.6077e-02, -2.1209e-02,  6.7284e-02,\n",
      "        -3.6328e-02, -2.7051e-02, -2.3753e-02, -2.4273e-02,  1.7732e-02,\n",
      "        -6.1965e-02, -1.4195e-02,  2.4942e-02,  4.2205e-03, -2.3527e-02,\n",
      "        -7.3326e-02,  1.0216e-02,  1.5060e-02,  3.6677e-02,  5.5809e-03,\n",
      "        -4.4983e-02,  7.7096e-03,  1.4566e-02,  2.0371e-02,  8.7477e-03,\n",
      "         6.8602e-02,  4.8339e-03, -1.6572e-03,  3.1951e-02,  4.4277e-02,\n",
      "         2.3278e-02, -4.2795e-03, -3.3506e-03, -1.1913e-02, -2.6270e-02,\n",
      "        -2.5642e-02, -6.4233e-03,  1.4751e-02, -1.7666e-02,  5.0741e-02,\n",
      "         2.3628e-02, -2.4669e-02,  2.2688e-03, -7.7042e-03, -3.0165e-02,\n",
      "        -3.5141e-02, -4.6791e-02, -5.4663e-02, -2.6287e-02, -9.8773e-03,\n",
      "         1.7585e-02,  1.0150e-02, -1.1151e-03, -2.3725e-02, -4.7588e-02,\n",
      "        -2.5135e-02, -6.0039e-03, -2.2198e-02, -3.3325e-02, -3.3289e-04,\n",
      "         2.9509e-03,  2.3489e-02,  5.3285e-02, -2.4127e-02,  4.9094e-02,\n",
      "        -2.9090e-02, -2.1021e-02, -3.5175e-02,  2.3342e-02,  7.8686e-02,\n",
      "         3.5152e-02, -9.2479e-03, -1.9112e-03,  3.3678e-03,  5.2234e-03,\n",
      "         8.9738e-03, -3.3619e-02], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPVisionModelWithProjection\n",
    "\n",
    "model = CLIPVisionModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\")\n",
    "model = model.eval()\n",
    "visual_output = model(video)\n",
    "\n",
    "# Normalizing the embeddings and calculating mean between all embeddings\n",
    "visual_output = visual_output[\"image_embeds\"]\n",
    "visual_output = visual_output / visual_output.norm(dim=-1, keepdim=True)\n",
    "visual_output = torch.mean(visual_output, dim=0)\n",
    "visual_output = visual_output / visual_output.norm(dim=-1, keepdim=True)\n",
    "print(visual_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f135bfd",
   "metadata": {},
   "source": [
    "# MAFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beedd5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的设备 (Using device): cuda\n",
      "正在加载模型 (Loading models)...\n",
      "模型加载完成 (Models loaded).\n",
      "正在读取标签文件 (Reading label file): /home/peterchen/M2/ADEPT/data/mafw/labels/sampled_850.xlsx\n",
      "找到了 850 个有效的视频-文本对 (Found 850 valid video-text pairs).\n",
      "开始提取特征 (Starting feature extraction)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理视频中 (Processing Videos):  13%|█▎        | 108/850 [00:41<01:47,  6.89it/s][h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "[h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "[h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "[h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "[h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "[h264 @ 0x561d08330500] error while decoding MB 72 39, bytestream -7\n",
      "处理视频中 (Processing Videos):  19%|█▊        | 158/850 [01:00<03:39,  3.16it/s][mpeg4 @ 0x561d0516b100] slice end not reached but screenspace end (3 left C00000, score= -9)\n",
      "[mpeg4 @ 0x561cfb797700] slice end not reached but screenspace end (3 left C00000, score= -10)\n",
      "处理视频中 (Processing Videos): 100%|██████████| 850/850 [05:46<00:00,  2.45it/s]\n",
      "处理文本中 (Processing Texts): 100%|██████████| 850/850 [00:12<00:00, 69.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征提取完成，开始计算评估指标 (Feature extraction complete. Calculating metrics)...\n",
      "--- 评估结果 (Evaluation Results) ---\n",
      "相似度矩阵形状 (Similarity-matrix shape): (850, 850)\n",
      "文本->视频检索 (Text-to-Video): R@1: 6.6% - R@5: 15.6% - R@10: 21.6% - Median R: 75.0 - Mean R: 129.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, InterpolationMode\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPVisionModelWithProjection, CLIPTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "# --- 1. 设置与参数定义 (Setup and Parameters) ---\n",
    "\n",
    "# 请根据您的实际环境修改这些路径\n",
    "VIDEO_BASE_PATH = '/home/peterchen/M2/ADEPT/data/mafw/videos'\n",
    "LABEL_FILE_PATH = '/home/peterchen/M2/ADEPT/data/mafw/labels/sampled_850.xlsx'\n",
    "MODEL_NAME = \"Searchium-ai/clip4clip-webvid150k\"\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"当前使用的设备 (Using device): {DEVICE}\")\n",
    "\n",
    "# --- 2. 视频与文本编码函数 (Video and Text Encoding Functions) ---\n",
    "\n",
    "# 视频编码函数 (与您提供的代码一致)\n",
    "def video2image(video_path, frame_rate=1.0, size=224):\n",
    "    def preprocess(size, n_px):\n",
    "        return Compose([\n",
    "            Resize(size, interpolation=InterpolationMode.BICUBIC),\n",
    "            CenterCrop(size),\n",
    "            lambda image: image.convert(\"RGB\"),\n",
    "            ToTensor(),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])(n_px)\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"错误: 视频文件不存在 (ERROR: Video file not found): {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    images = []\n",
    "    if fps > 0:\n",
    "        total_duration = (frameCount + fps - 1) // fps\n",
    "        interval = fps / frame_rate\n",
    "        frames_idx = np.floor(np.arange(0, total_duration * fps, interval))\n",
    "        \n",
    "        for idx in frames_idx:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            images.append(preprocess(size, Image.fromarray(frame).convert(\"RGB\")))\n",
    "    else:\n",
    "        print(f\"警告: 无法读取视频FPS (WARNING: Could not read FPS for video): {video_path}\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not images:\n",
    "        print(f\"错误: 无法从视频中提取帧 (ERROR: Could not extract frames from video): {video_path}\")\n",
    "        return None\n",
    "        \n",
    "    video_frames = torch.stack(images)\n",
    "    return video_frames\n",
    "\n",
    "# --- 3. 评估指标计算函数 (Evaluation Metrics Function) ---\n",
    "\n",
    "# 指标计算函数 (与教程中的代码一致)\n",
    "def compute_metrics(sim_matrix):\n",
    "    # sim_matrix 的形状应为 (N_texts, N_videos)\n",
    "    # 假设文本和视频是一一对应的, 所以理想情况下对角线元素值最大\n",
    "    nn_idx = np.argsort(-sim_matrix, axis=1)\n",
    "    \n",
    "    # 创建一个单位矩阵作为理想的排序结果\n",
    "    y = np.eye(nn_idx.shape[0])\n",
    "    \n",
    "    # 找到每个文本的正确视频匹配项在排序列表中的位置\n",
    "    ind = np.where(np.take_along_axis(y, nn_idx, axis=1) == 1)[1]\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['R1'] = float(np.sum(ind == 0)) * 100 / len(ind)\n",
    "    metrics['R5'] = float(np.sum(ind < 5)) * 100 / len(ind)\n",
    "    metrics['R10'] = float(np.sum(ind < 10)) * 100 / len(ind)\n",
    "    metrics['MR'] = np.median(ind) + 1\n",
    "    metrics[\"MedianR\"] = metrics['MR']\n",
    "    metrics[\"MeanR\"] = np.mean(ind) + 1\n",
    "\n",
    "    print('--- 评估结果 (Evaluation Results) ---')\n",
    "    print(f'相似度矩阵形状 (Similarity-matrix shape): {nn_idx.shape}')\n",
    "    result_str = (\n",
    "        f\"文本->视频检索 (Text-to-Video): \"\n",
    "        f\"R@1: {metrics['R1']:.2f}% - \"\n",
    "        f\"R@5: {metrics['R5']:.2f}% - \"\n",
    "        f\"R@10: {metrics['R10']:.2f}% - \"\n",
    "        f\"Median R: {metrics['MR']:.2f} - \"\n",
    "        f\"Mean R: {metrics['MeanR']:.2f}\"\n",
    "    )\n",
    "    print(result_str)\n",
    "\n",
    "    # 保存到txt文件\n",
    "    with open(\"/home/peterchen/M2/Clip4Clip/metrics_mafw_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write('--- 评估结果 (Evaluation Results) ---\\n')\n",
    "        f.write(f'相似度矩阵形状 (Similarity-matrix shape): {nn_idx.shape}\\n')\n",
    "        f.write(result_str + \"\\n\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# --- 4. 主执行流程 (Main Execution Workflow) ---\n",
    "\n",
    "def main():\n",
    "    # --- 步骤 1: 加载模型 ---\n",
    "    print(\"正在加载模型 (Loading models)...\")\n",
    "    video_model = CLIPVisionModelWithProjection.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "    text_model = CLIPTextModelWithProjection.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(MODEL_NAME)\n",
    "    video_model.eval()\n",
    "    text_model.eval()\n",
    "    print(\"模型加载完成 (Models loaded).\")\n",
    "\n",
    "    # --- 步骤 2: 加载数据标签 ---\n",
    "    print(f\"正在读取标签文件 (Reading label file): {LABEL_FILE_PATH}\")\n",
    "    df = pd.read_excel(LABEL_FILE_PATH)\n",
    "    # 为确保一一对应, 移除缺少视频名或标题的行\n",
    "    df.dropna(subset=['video_name', 'eng_caption'], inplace=True)\n",
    "    video_names = df['video_name'].tolist()\n",
    "    captions = df['eng_caption'].tolist()\n",
    "    print(f\"找到了 {len(video_names)} 个有效的视频-文本对 (Found {len(video_names)} valid video-text pairs).\")\n",
    "\n",
    "    # --- 步骤 3: 提取所有视频和文本的特征 ---\n",
    "    all_video_embeds = []\n",
    "    all_text_embeds = []\n",
    "    \n",
    "    print(\"开始提取特征 (Starting feature extraction)...\")\n",
    "    with torch.no_grad():\n",
    "        # 提取视频特征\n",
    "        for video_name in tqdm(video_names, desc=\"处理视频中 (Processing Videos)\"):\n",
    "            video_path = os.path.join(VIDEO_BASE_PATH, video_name)\n",
    "            video_frames = video2image(video_path)\n",
    "            \n",
    "            if video_frames is None:\n",
    "                # 如果视频处理失败, 添加一个零向量作为占位符\n",
    "                # 在后续分析中可以考虑如何处理这些失败案例\n",
    "                all_video_embeds.append(torch.zeros(512).to(DEVICE))\n",
    "                continue\n",
    "            \n",
    "            video_frames = video_frames.to(DEVICE)\n",
    "            visual_output = video_model(video_frames)\n",
    "            \n",
    "            # 归一化并取均值\n",
    "            visual_embeds = visual_output[\"image_embeds\"]\n",
    "            visual_embeds = visual_embeds / visual_embeds.norm(dim=-1, keepdim=True)\n",
    "            visual_embeds = torch.mean(visual_embeds, dim=0)\n",
    "            visual_embeds = visual_embeds / visual_embeds.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            all_video_embeds.append(visual_embeds)\n",
    "            \n",
    "        # 提取文本特征\n",
    "        for caption in tqdm(captions, desc=\"处理文本中 (Processing Texts)\"):\n",
    "            inputs = tokenizer(text=caption, return_tensors=\"pt\").to(DEVICE)\n",
    "            text_output = text_model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "            \n",
    "            # 归一化\n",
    "            text_embed = text_output[0] / text_output[0].norm(dim=-1, keepdim=True)\n",
    "            all_text_embeds.append(text_embed.squeeze(0))\n",
    "\n",
    "    # --- 步骤 4: 计算相似度并评估 ---\n",
    "    print(\"特征提取完成，开始计算评估指标 (Feature extraction complete. Calculating metrics)...\")\n",
    "    \n",
    "    # 将列表转换为张量\n",
    "    video_embeddings_tensor = torch.stack(all_video_embeds).cpu().numpy()\n",
    "    text_embeddings_tensor = torch.stack(all_text_embeds).cpu().numpy()\n",
    "\n",
    "    # 计算相似度矩阵 (文本 x 视频)\n",
    "    similarity_matrix = np.matmul(text_embeddings_tensor, video_embeddings_tensor.T)\n",
    "\n",
    "    # 计算并打印评估指标\n",
    "    compute_metrics(similarity_matrix)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae3c5a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m文本->视频检索 (Text-to-Video): R@1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% - R@5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR5\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% - R@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR10\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% - Median R: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Mean R: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeanR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"文本->视频检索 (Text-to-Video): R@1: {metrics['R1']:.2f}% - R@5: {metrics['R5']:.2f}% - R@10: {metrics['R10']:.2f}% - Median R: {metrics['MR']:.2f} - Mean R: {metrics['MeanR']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89bf38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>chinese</th>\n",
       "      <th>english</th>\n",
       "      <th>eng_caption</th>\n",
       "      <th>video_path</th>\n",
       "      <th>model_caption</th>\n",
       "      <th>processing_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_00000000</td>\n",
       "      <td>在视频中，开头的画面显示一位穿着医生服的男性角色，他的面部表情显得有些严肃和认真，眼神专注地...</td>\n",
       "      <td>In the video, the opening scene shows a male c...</td>\n",
       "      <td>In the video, the opening scene shows a male c...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A man with dark hair and a beard stands in a h...</td>\n",
       "      <td>7.151556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_00000007</td>\n",
       "      <td>在视频中，我们看到一位女士在室内环境中使用电话。她的面部表情显得愉悦，嘴角上扬，显示出她可能...</td>\n",
       "      <td>In the video, we see a lady using a phone in a...</td>\n",
       "      <td>In the video, we see a lady using a phone in a...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A woman with black hair, wearing a traditional...</td>\n",
       "      <td>7.189739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_00000021</td>\n",
       "      <td>在视频中，画面显示一位中年女性，她坐在凳子上，场景是室内，装修比较豪华。在视频中，她的面部表...</td>\n",
       "      <td>In the video, the screen shows a middle-aged w...</td>\n",
       "      <td>In the video, the screen shows a middle-aged w...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A woman with dark hair and visible identity cu...</td>\n",
       "      <td>5.931152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_00000033</td>\n",
       "      <td>在视频中，画面显示了一位男性的特写镜头。他的面部表情相对紧张，眉头紧锁，可能表明他正在经历一...</td>\n",
       "      <td>In the video, the screen shows a close-up shot...</td>\n",
       "      <td>In the video, the screen shows a close-up shot...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>In the video clip, a man with a serious expres...</td>\n",
       "      <td>5.498530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_00000039</td>\n",
       "      <td>在视频中，开头的画面中，我们看到一位女性角色站在室内环境中，她表情严肃，眼睛瞪圆，盯着对方，...</td>\n",
       "      <td>In the video, in the opening scene, we see a f...</td>\n",
       "      <td>In the video, in the opening scene, we see a f...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A woman with long dark hair stands in a room w...</td>\n",
       "      <td>5.195675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>sample_00003239</td>\n",
       "      <td>在视频中，画面显示一位男士正在使用手机通话，场景是室内。在视频开头，他一只手叉着腰，一只手拿...</td>\n",
       "      <td>In the video, the screen shows a man using a c...</td>\n",
       "      <td>In the video, the screen shows a man using a c...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A man with a black and white striped shirt sta...</td>\n",
       "      <td>6.186628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>sample_00003253</td>\n",
       "      <td>在视频中，画面显示两个角色坐在一张桌子旁，环境看起来像是一个室内的餐厅，我们主要分析女性的情...</td>\n",
       "      <td>In the video, the scene shows two characters s...</td>\n",
       "      <td>In the video, the scene shows two characters s...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A woman with long hair, wearing a pink dress, ...</td>\n",
       "      <td>7.187324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>sample_00003284</td>\n",
       "      <td>在视频中，画面显示一位中年女士正在打电话，从背景中的窗帘可以推测出场景是室内。在视频开头，她...</td>\n",
       "      <td>In the video, the screen shows a middle-aged w...</td>\n",
       "      <td>In the video, the screen shows a middle-aged w...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A woman with black hair, wearing a blue blouse...</td>\n",
       "      <td>5.629751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>sample_00003296</td>\n",
       "      <td>在视频中，画面显示一个穿着红色外套的小女孩，她的周围围着不少人，场景是室外。在视频中，她嘴角...</td>\n",
       "      <td>In the video, the screen shows a little girl w...</td>\n",
       "      <td>In the video, the screen shows a little girl w...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>In the scene, a man stands in a dimly lit room...</td>\n",
       "      <td>5.547124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>sample_00003298</td>\n",
       "      <td>在视频中，画面显示一位男性角色站在户外。在视频开头，他的身体姿态是直立的，眼神直视前方，似乎...</td>\n",
       "      <td>In the video, the screen shows a male characte...</td>\n",
       "      <td>In the video, the screen shows a male characte...</td>\n",
       "      <td>/home/peterchen/M2/MER2024/video-selected/samp...</td>\n",
       "      <td>A man with short, dark hair stands in a park, ...</td>\n",
       "      <td>6.559053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                                            chinese  \\\n",
       "0    sample_00000000  在视频中，开头的画面显示一位穿着医生服的男性角色，他的面部表情显得有些严肃和认真，眼神专注地...   \n",
       "1    sample_00000007  在视频中，我们看到一位女士在室内环境中使用电话。她的面部表情显得愉悦，嘴角上扬，显示出她可能...   \n",
       "2    sample_00000021  在视频中，画面显示一位中年女性，她坐在凳子上，场景是室内，装修比较豪华。在视频中，她的面部表...   \n",
       "3    sample_00000033  在视频中，画面显示了一位男性的特写镜头。他的面部表情相对紧张，眉头紧锁，可能表明他正在经历一...   \n",
       "4    sample_00000039  在视频中，开头的画面中，我们看到一位女性角色站在室内环境中，她表情严肃，眼睛瞪圆，盯着对方，...   \n",
       "..               ...                                                ...   \n",
       "327  sample_00003239  在视频中，画面显示一位男士正在使用手机通话，场景是室内。在视频开头，他一只手叉着腰，一只手拿...   \n",
       "328  sample_00003253  在视频中，画面显示两个角色坐在一张桌子旁，环境看起来像是一个室内的餐厅，我们主要分析女性的情...   \n",
       "329  sample_00003284  在视频中，画面显示一位中年女士正在打电话，从背景中的窗帘可以推测出场景是室内。在视频开头，她...   \n",
       "330  sample_00003296  在视频中，画面显示一个穿着红色外套的小女孩，她的周围围着不少人，场景是室外。在视频中，她嘴角...   \n",
       "331  sample_00003298  在视频中，画面显示一位男性角色站在户外。在视频开头，他的身体姿态是直立的，眼神直视前方，似乎...   \n",
       "\n",
       "                                               english  \\\n",
       "0    In the video, the opening scene shows a male c...   \n",
       "1    In the video, we see a lady using a phone in a...   \n",
       "2    In the video, the screen shows a middle-aged w...   \n",
       "3    In the video, the screen shows a close-up shot...   \n",
       "4    In the video, in the opening scene, we see a f...   \n",
       "..                                                 ...   \n",
       "327  In the video, the screen shows a man using a c...   \n",
       "328  In the video, the scene shows two characters s...   \n",
       "329  In the video, the screen shows a middle-aged w...   \n",
       "330  In the video, the screen shows a little girl w...   \n",
       "331  In the video, the screen shows a male characte...   \n",
       "\n",
       "                                           eng_caption  \\\n",
       "0    In the video, the opening scene shows a male c...   \n",
       "1    In the video, we see a lady using a phone in a...   \n",
       "2    In the video, the screen shows a middle-aged w...   \n",
       "3    In the video, the screen shows a close-up shot...   \n",
       "4    In the video, in the opening scene, we see a f...   \n",
       "..                                                 ...   \n",
       "327  In the video, the screen shows a man using a c...   \n",
       "328  In the video, the scene shows two characters s...   \n",
       "329  In the video, the screen shows a middle-aged w...   \n",
       "330  In the video, the screen shows a little girl w...   \n",
       "331  In the video, the screen shows a male characte...   \n",
       "\n",
       "                                            video_path  \\\n",
       "0    /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "1    /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "2    /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "3    /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "4    /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "..                                                 ...   \n",
       "327  /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "328  /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "329  /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "330  /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "331  /home/peterchen/M2/MER2024/video-selected/samp...   \n",
       "\n",
       "                                         model_caption  processing_time  \n",
       "0    A man with dark hair and a beard stands in a h...         7.151556  \n",
       "1    A woman with black hair, wearing a traditional...         7.189739  \n",
       "2    A woman with dark hair and visible identity cu...         5.931152  \n",
       "3    In the video clip, a man with a serious expres...         5.498530  \n",
       "4    A woman with long dark hair stands in a room w...         5.195675  \n",
       "..                                                 ...              ...  \n",
       "327  A man with a black and white striped shirt sta...         6.186628  \n",
       "328  A woman with long hair, wearing a pink dress, ...         7.187324  \n",
       "329  A woman with black hair, wearing a blue blouse...         5.629751  \n",
       "330  In the scene, a man stands in a dimly lit room...         5.547124  \n",
       "331  A man with short, dark hair stands in a park, ...         6.559053  \n",
       "\n",
       "[332 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_excel(\"/home/peterchen/M2/MER2024/llava_next_video_caption.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
