import os
import torch
import numpy as np
import pandas as pd
import faiss
import pickle
from tqdm import tqdm
from openai import OpenAI
from transformers import AutoTokenizer
import sys
sys.path.append("/home/peterchen/M2/contriever")
from src.contriever import Contriever

# é…ç½®
MAX_ROUNDS = 5  # æœ€å¤§äº¤äº’è½®æ¬¡
TOP_K = 10      # æ£€ç´¢ç»“æœæ•°é‡/æˆåŠŸé˜ˆå€¼ï¼ˆå½“æ’å<=æ­¤å€¼æ—¶æå‰ç»“æŸï¼‰
OPENAI_BASE_URL = "https://api.deepseek.com"
OPENAI_API_KEY = "sk-3e3bc603ac9647af91919f2cd57efbf5"
LLM_MODEL = "deepseek-chat"
MAX_SEARCH_LIMIT = None  # å¤§å‹è§†é¢‘åº“æœç´¢ä¸Šé™ï¼Œè®¾ä¸ºNoneåˆ™æœç´¢å…¨éƒ¨

class InteractiveVideoRetrievalSystem:
    def __init__(self, caption_file, faiss_index_path=None, id2video_path=None):
        # åˆå§‹åŒ–äº¤äº’å¼è§†é¢‘æ£€ç´¢ç³»ç»Ÿ
        print(f"æ­£åœ¨è¯»å– Excel æ–‡ä»¶: {caption_file}")
        self.caption_df = pd.read_excel(caption_file)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¿…è¦çš„åˆ—
        if "name" not in self.caption_df.columns or "model_caption" not in self.caption_df.columns:
            raise ValueError("Excel æ–‡ä»¶ä¸­å¿…é¡»åŒ…å« 'name' å’Œ 'model_caption' åˆ—")
        
        #  è¿‡æ»¤æ‰ç©ºçš„ caption
        self.caption_df = self.caption_df.dropna(subset=['model_caption'])
        
        # åˆ›å»º video_name åˆ° caption çš„æ˜ å°„
        self.video_to_caption = dict(zip(self.caption_df['name'], self.caption_df['model_caption']))
        print(f"åŠ è½½äº† {len(self.video_to_caption)} ä¸ªè§†é¢‘çš„ caption")
        
        # åˆå§‹åŒ– Contriever æ¨¡å‹å’Œ tokenizer
        self.contriever, self.tokenizer = self.load_contriever()
        
        # åˆ›å»ºæˆ–åŠ è½½ FAISS ç´¢å¼•
        self.faiss_index_path = faiss_index_path
        self.id2video_path = id2video_path
        
        if faiss_index_path and id2video_path and os.path.exists(faiss_index_path) and os.path.exists(id2video_path):
            print(f"åŠ è½½ FAISS ç´¢å¼•: {faiss_index_path}")
            self.faiss_index = faiss.read_index(faiss_index_path)
            with open(id2video_path, 'rb') as f:
                self.id2video = pickle.load(f)
            print(f"æˆåŠŸåŠ è½½ç´¢å¼•ï¼ŒåŒ…å«{self.faiss_index.ntotal}ä¸ªè§†é¢‘")
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            print("\n=== è°ƒè¯•: FAISSç´¢å¼•åŠ è½½ ===")
            print(f"ç´¢å¼•ç±»å‹: {type(self.faiss_index)}")
            print(f"å‘é‡ç»´åº¦: {self.faiss_index.d}")
            print(f"id2videoç±»å‹: {type(self.id2video)}")
            print(f"id2videoå¤§å°: {len(self.id2video)}")
            if len(self.id2video) > 0:
                id_samples = list(self.id2video.items())[:5]
                print(f"id2videoæ ·ä¾‹(å‰5é¡¹): {id_samples}")
                # æ£€æŸ¥IDæ ¼å¼
                has_extension = ['.mp4' in str(v) or '.avi' in str(v) or '.mov' in str(v) for k,v in id_samples]
                print(f"ç¤ºä¾‹IDæ˜¯å¦åŒ…å«æ‰©å±•å: {has_extension}")
            
            # åå‘åˆ›å»º video åˆ° id çš„æ˜ å°„
            self.video2id = {v:k for k, v in self.id2video.items()}
            print(f"video2idå¤§å°: {len(self.video2id)}")
            # æ£€æŸ¥æ‰©å±•åä¸æ˜ å°„çš„å…³ç³»
            key_with_ext = [k for k in list(self.video2id.keys())[:20] if '.' in str(k)]
            print(f"å‰20ä¸ªkeyä¸­å¸¦æ‰©å±•åçš„æ•°é‡: {len(key_with_ext)}")
            if len(key_with_ext) > 0:
                print(f"å¸¦æ‰©å±•åçš„keyæ ·ä¾‹: {key_with_ext[:3]}")
        else:
            print("åˆ›å»ºæ–°çš„ FAISS ç´¢å¼•")
            self.id2video, self.video2id, self.faiss_index = self.build_faiss_index()
            
            # ä¿å­˜ç´¢å¼•å’Œæ˜ å°„
            if faiss_index_path and id2video_path:
                os.makedirs(os.path.dirname(faiss_index_path), exist_ok=True)
                os.makedirs(os.path.dirname(id2video_path), exist_ok=True)
                
                faiss.write_index(self.faiss_index, faiss_index_path)
                with open(id2video_path, "wb") as f:
                    pickle.dump(self.id2video, f)
                print(f"FAISS ç´¢å¼•å·²ä¿å­˜è‡³: {faiss_index_path}")
                print(f"ID æ˜ å°„å·²ä¿å­˜è‡³ï¼š{id2video_path}")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = OpenAI(
             api_key=OPENAI_API_KEY,
             base_url=OPENAI_BASE_URL,
        )
    
    def load_contriever(self):
        # åŠ è½½ Contriever æ¨¡å‹å’Œ tokenizer
        print("åŠ è½½ Contriever æ¨¡å‹å’Œ tokenizer")
        model = Contriever.from_pretrained("facebook/contriever")
        tokenizer = AutoTokenizer.from_pretrained("facebook/contriever")
        
        model.eval()
        # è½¬ç§»åˆ° GPU
        if torch.cuda.is_available():
            model = model.cuda()
        return model, tokenizer
        
    def encode_text(self, texts):
        # ä½¿ç”¨ Contriever ç¼–ç æ–‡æœ¬
        if isinstance(texts, str):
            texts = [texts]
        texts = [t for t in texts if isinstance(t, str) and t.strip()]
        if not texts:
            return np.array([])

        # ä½¿ç”¨ tokenizer ç¼–ç 
        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
        
        # æŠŠè¾“å…¥è½¬ç§»åˆ° GPU
        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        # ä½¿ç”¨æ¨¡å‹ç”ŸæˆåµŒå…¥
        with torch.no_grad():
            embeddings = self.contriever(**inputs)
            
            # å°†å¼ é‡ç§»åˆ°CPUå¹¶è½¬æ¢ä¸ºNumPyæ•°ç»„
            if torch.cuda.is_available():
                embeddings = embeddings.cpu()
            embeddings = embeddings.numpy()
            
            # å½’ä¸€åŒ–å‘é‡ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
            embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
        
        return embeddings
    
    def build_faiss_index(self):
        # æ„å»º FAISS ç´¢å¼•å¹¶è¿”å› id2video æ˜ å°„
        video_names = list(self.video_to_caption.keys())
        captions = list(self.video_to_caption.values())
        print(f"æ­£åœ¨å¯¹{len(captions)}ä¸ªè§†é¢‘è¿›è¡Œç¼–ç ...")
        
        # æ‰¹é‡ç¼–ç 
        batch_size = 128
        all_embeddings = []
        
        for i in tqdm(range(0, len(captions), batch_size)):
            batch_captions = captions[i:i+batch_size]
            batch_embeddings = self.encode_text(batch_captions)
            if len(batch_embeddings) > 0:
                all_embeddings.append(batch_embeddings)
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„åµŒå…¥
        if not all_embeddings:
            raise ValueError("æ— æ³•ç¼–ç ä»»ä½• caption, è¯·æ£€æŸ¥æ•°æ®")

        embeddings = np.vstack(all_embeddings)
        
        # åˆ›å»º ID åˆ°è§†é¢‘çš„æ˜ å°„
        id2video = {i: video_names[i] for i in range(len(video_names))}
        video2id = {v: k for k,v in id2video.items()}
        
        # åˆ›å»º FAISS ç´¢å¼•
        d = embeddings.shape[1]
        index = faiss.IndexFlatIP(d)
        index.add(embeddings)
        
        print(f"FAISS ç´¢å¼•å·²åˆ›å»ºï¼ŒåŒ…å« {index.ntotal} ä¸ªå‘é‡")
        return id2video, video2id, index
    
    def retrieve_videos(self, query, k=TOP_K, query_embedding=None):
        # æ£€ç´¢ä¸æŸ¥è¯¢æœ€ç›¸ä¼¼çš„å‰ k ä¸ªè§†é¢‘
        if query_embedding is None:
            query_embedding = self.encode_text([query])
        
        if len(query_embedding) == 0:
            print(f"è­¦å‘Š: æ— æ³•ç¼–ç æŸ¥è¯¢ï¼š{query}")
            return []

        # æ£€ç´¢æœ€ç›¸ä¼¼çš„è§†é¢‘
        distances, indices = self.faiss_index.search(query_embedding, k)
        print(f"FAISSæ£€ç´¢åˆ° {len(indices[0])} ä¸ªç»“æœ")
        
        # è½¬æ¢ä¸ºç»“æœåˆ—è¡¨
        results = []
        for i, idx in enumerate(indices[0]):
            if idx >= 0 and idx < len(self.id2video):
                video_id = self.id2video[idx]
                score = float(distances[0][i])
                caption = self.video_to_caption.get(video_id, "")
                results.append({
                    "video_id": video_id,
                    "score": score,
                    "caption": caption,
                })
        
        print(f"æˆåŠŸè½¬æ¢ {len(results)} ä¸ªç»“æœåˆ°å­—å…¸")
        if len(results) > 0:
            print(f"å‰5ä¸ªç»“æœ:")
            for i, res in enumerate(results[:5]):
                print(f"  {i+1}. ID: '{res['video_id']}' (å¾—åˆ†: {res['score']:.4f})")
                print(f"     æè¿°: {res['caption'][:100]}...")
        
        return results
    
    def find_target_rank(self, target_video_id, query_embedding, top_captions=None, top_k=TOP_K):
        """æ‰¾å‡ºç›®æ ‡è§†é¢‘åœ¨æ£€ç´¢ç»“æœä¸­çš„æ’å"""
        if target_video_id is None:
            return None
        
        # ç®€å•æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"æŸ¥æ‰¾ç›®æ ‡ID: '{target_video_id}'")
        
        try:
            # è·å–ç´¢å¼•ä¸­çš„æ€»è§†é¢‘æ•°é‡
            total_videos = self.faiss_index.ntotal
            
            # æœç´¢æ•´ä¸ªç´¢å¼•ä»¥è·å–å®Œæ•´æ’å
            distances, indices = self.faiss_index.search(query_embedding, total_videos)
            all_video_ids = [self.id2video[idx] for idx in indices[0] if idx >= 0 and idx < len(self.id2video)]
            
            print(f"æœç´¢äº†æ•´ä¸ªç´¢å¼•ï¼Œå…±{len(all_video_ids)}ä¸ªè§†é¢‘")
            print(f"æ£€ç´¢ç»“æœIDç¤ºä¾‹: {all_video_ids[:3]}")
        
        # ç›´æ¥åŒ¹é…ï¼šæ£€æŸ¥ç›®æ ‡IDæ˜¯å¦åœ¨æ£€ç´¢ç»“æœä¸­
            if target_video_id in all_video_ids:
                global_rank = all_video_ids.index(target_video_id) + 1
                print(f"ç›®æ ‡è§†é¢‘ç²¾ç¡®åŒ¹é…æˆåŠŸ! æ’å: {global_rank}/{len(all_video_ids)}")
                return global_rank
            
        # å¦‚æœæ²¡æœ‰ç›´æ¥åŒ¹é…ï¼Œå°è¯•ä¸åŒºåˆ†æ‰©å±•åçš„åŒ¹é…
        # å°†ç›®æ ‡IDå’Œæ£€ç´¢ç»“æœIDéƒ½å¤„ç†ä¸ºæ— æ‰©å±•åå½¢å¼
        target_base_id = os.path.splitext(target_video_id)[0] if '.' in target_video_id else target_video_id
        
            for i, vid in enumerate(all_video_ids):
            vid_base = os.path.splitext(vid)[0] if '.' in vid else vid
            if vid_base == target_base_id:
                    global_rank = i + 1
                    print(f"ç›®æ ‡è§†é¢‘åŸºç¡€ååŒ¹é…æˆåŠŸ! æ’å: {global_rank}/{len(all_video_ids)}")
                    return global_rank
        
        print(f"ç›®æ ‡è§†é¢‘ä¸åœ¨æ£€ç´¢ç»“æœä¸­")
        return None
            
        except Exception as e:
            print(f"æœç´¢å…¨éƒ¨ç´¢å¼•æ—¶å‡ºé”™: {e}")
            return None
    
    def generate_question(self, query, top_k_videos, conversation_history=None):
        # ç”Ÿæˆå…³äºè§†é¢‘çš„é—®é¢˜
        similarity_scores = [video["score"] for video in top_k_videos if "score" in video]
        if not similarity_scores:
            similarity_scores = [0.5]*len(top_k_videos)
        
        # Step 1: åˆ¤æ–­å¬å›ç»“æœçš„è´¨é‡
        avg_sim = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0    
        low_quality = avg_sim < 0.15
        
        # Step 2: åˆ¤æ–­æ˜¯å¦æ˜¯ç¬¬ä¸€è½®äº¤äº’
        round_num = len(conversation_history) if conversation_history else 0
        is_first_round = (round_num == 0)
        
        # Step 3: è§†é¢‘æè¿°æ‹¼æ¥
        video_descriptions = []
        for i, video in enumerate(top_k_videos):
            caption = video.get("caption", "")
            video_descriptions.append(f"è§†é¢‘ {i+1}: {caption}")
        
        videos_text = "\n".join(video_descriptions)
        
        # Step 4: å†å²å¯¹è¯æ‹¼æ¥
        history_text = ""
        if conversation_history:
            for i, exchange in enumerate(conversation_history):
                history_text += f"é—®é¢˜ {i+1}: {exchange['question']}\n"
                history_text += f"å›ç­” {i+1}: {exchange['answer']}\n"
        
        history_display = ""
        if history_text:
            history_display = " ä¹‹å‰çš„å¯¹è¯å†å²:\n" + history_text
        
        # Step 5: æ ¹æ®åˆ¤æ–­æ„å»º Prompt
        if low_quality:
            if is_first_round:
                # ç¬¬ä¸€è½® + å€™é€‰è´¨é‡ä½ï¼šæ„å›¾æ¾„æ¸…æ¨¡å¼
                prompt = f"""
                    Your task is to improve video search by generating a specific and effective question.

                    Original query: "{query}"
                    The initial search results were of low quality. Please generate a clear and focused question that can guide the search better. If your first attempt is not effective, generate a different question to try again.

                    Your question should meet the following requirements:
                    1. Ask about specific visual elements, such as objects, people, actions, facial expressions, or scenes.
                    2. Help clarify what makes the target video distinct or unique compared to others.
                    3. Ask for observable, factual detailsâ€”something that can be seen or confirmed in the video (e.g., "Is the person smiling?" or "What color is the car?"), not personal opinions or abstract descriptions.

                    Return only the question itself. Do not include explanations or additional comments.
                """
            else:
                # åç»­è½®æ¬¡ + å€™é€‰ä¾ç„¶ä½è´¨é‡ â†’ fallback æé—®ï¼ˆç»§ç»­æ¾„æ¸…æ„å›¾ï¼‰
                prompt = f"""
                    You are helping to improve video search. After {round_num} rounds, the correct video still hasn't been found and current results are low quality.

                    Original query: "{query}"
                    Previous conversation:{history_text}

                    Ask a new question focusing on visual aspects not yet mentioned.
                    Prioritize specific details such as:
                    - Number of people
                    - Specific objects, animals, or text
                    - Colors of key items
                    - Type of location or setting
                    - Facial expressions or actions

                    Return only the question itself. No explanation.
                """
        else:
            # å€™é€‰è´¨é‡ OKï¼šç”ŸæˆåŒºåˆ†æ€§é—®é¢˜ï¼ˆåŸæœ‰é€»è¾‘ä¼˜åŒ–ç‰ˆï¼‰
            prompt = f"""
                You are analyzing {len(top_k_videos)} video descriptions to help find a specific video.

                Original query: "{query}"

                Video descriptions:
                {videos_text}
                {history_display}

                We are in a later round of search, and these videos still look similar but have subtle differences. Please ask a new question to help narrow down the correct video.
                
                Rules:
                - Focus on visual differences between videos (objects, people, counts, colors, actions, facial expressions)
                - Ask about elements that vary across multiple videos
                - Question must be specific and fact-based (not subjective or vague)
                - Avoid yes/no questions or repeating earlier ones
                - Keep it simple and direct

                Return only the question itself. No explanation.
            """
        # Step 6: è°ƒç”¨ LLM ç”Ÿæˆé—®é¢˜
        try:
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages = [{
                    "role": "user",
                    "content": prompt
                }],
                temperature=0.4,
                max_tokens=100,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"ç”Ÿæˆé—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "è¿™ä¸ªè§†é¢‘é‡Œæœ‰ä»€ä¹ˆå†…å®¹?"

    def generate_answer(self, query, question, video_description):
        prompt = f"""
        You are playing the role of a video viewer. Answer the question based on the given video description.
        
        Video description: {video_description}
        Question: {question}
        
        Rules:
        1. Your answer must be completely based on facts from the video description
        2. If not mentioned in the video description, answer "Not sure"
        3. Keep your answer concise, no more than 20 characters
        4. Do not explain your answer
        
        Only return your short answer.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages = [{
                    "role": "user",
                    "content": prompt
                }],
                temperature=0.1,
                max_tokens=50,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "ä¸ç¡®å®š"
    
    def generate_summary(self, query, conversation_history, top_k_captions, target_caption=None):
        # åˆ›å»ºæè¿°æ‰€æœ‰è§†é¢‘çš„æ–‡æœ¬
        video_descriptions = ""
        for i, caption in enumerate(top_k_captions):
            video_descriptions += f"è§†é¢‘ {i+1}: {caption}\n"
        
        # åˆ›å»ºå¯¹è¯å†å²çš„æ–‡æœ¬
        history_text = ""
        for i, exchange in enumerate(conversation_history):
            history_text += f"é—®é¢˜ {i+1}: {exchange['question']}\n"
            history_text += f"å›ç­” {i+1}: {exchange['answer']}\n"
        
        prompt = f"""
            You are a video retrieval assistant helping a user find a specific video.

            Original query: {query}

            Conversation history:
            {history_text}

            Current search results (ranked by relevance):
            {video_descriptions}

            Please generate a concise summary for the next round, including:
            - What the user is originally looking for
            - All known visual details about the target video so far (e.g., people, actions, objects, expressions, settings)
            - What key information is still missing and should be asked next

            Keep the summary clear and focused, no more than 5 sentences.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages=[{
                    "role": "user", 
                    "content": prompt
                }],
                temperature=0.3,
                max_tokens=150,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"ç”Ÿæˆæ€»ç»“æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "æ— æ³•ç”Ÿæˆæ€»ç»“ã€‚è¯·é‡è¯•æˆ–ç›´æ¥æé—®ã€‚"
    
    def update_query(self, current_query, question, answer, current_rank=None, best_rank=None):
        stats_info = ""
        if current_rank and best_rank:
            stats_info = f"å½“å‰ç›®æ ‡è§†é¢‘æ’å: {current_rank}, æœ€ä½³æ’å: {best_rank}ã€‚"
        
        prompt = f"""
            You are part of a video retrieval system. Update the search query to better match the video the user is looking for.

            Current query: {current_query}

            Latest interaction:
            Question: {question}
            Answer: {answer}

            {stats_info}

            Task:
            Update the query using key visual details from the user's answer (e.g., objects, people, actions, facial expressions, settings).

            Rules:
            - Keep core ideas from the original query
            - Add confirmed new details (e.g., appearance, expressions, gestures)
            - Remove elements the user said are not present
            - Focus on concrete visual content, not abstract ideas
            - Keep it concise â€” fewer than 20 words

            Return only the updated query text. No explanation.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=LLM_MODEL,
                messages=[{
                    "role": "user",
                    "content": prompt
                }],
                temperature=0.2,
                max_tokens=100,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"æ›´æ–°æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return current_query
    
    def run_interactive_retrieval(self, query, video_captions, target_video_id=None, max_turns=MAX_ROUNDS):
        # åˆå§‹åŒ–çŠ¶æ€å˜é‡
        best_rank = float('inf')
        best_turn = -1  # è®°å½•æœ€ä½³æ’åå‡ºç°çš„è½®æ¬¡
        best_query = ""  # è®°å½•æœ€ä½³æ’åå¯¹åº”çš„æŸ¥è¯¢
        best_top_videos = []  # è®°å½•æœ€ä½³æ’åæ—¶çš„topè§†é¢‘
        conversation_history = []
        expanded_query = query
        
        # æ‰“å°åŸºæœ¬è°ƒè¯•ä¿¡æ¯
        print(f"æŸ¥è¯¢: '{query}'")
        print(f"ç›®æ ‡è§†é¢‘ID: '{target_video_id}'")
        
        # åˆå§‹æœç´¢
        query_embedding = self.encode_text([expanded_query])
        top_k_videos = self.retrieve_videos(expanded_query, TOP_K, query_embedding)
        
        # å¦‚æœæœ‰ç›®æ ‡è§†é¢‘ï¼Œè®¡ç®—åˆå§‹æ’å - æœç´¢å…¨éƒ¨è§†é¢‘ä»¥è·å–å‡†ç¡®æ’å
        current_rank = None
        if target_video_id is not None:
            current_rank = self.find_target_rank(target_video_id, query_embedding)
            if current_rank is not None:
                print(f"åˆå§‹æ’å: {current_rank}")
                best_rank = current_rank
            else:
                print(f"é”™è¯¯ï¼šç›®æ ‡è§†é¢‘æœªåœ¨æ£€ç´¢ç»“æœä¸­æ‰¾åˆ°ï¼Œè¿™ä¸åº”è¯¥å‘ç”Ÿ")
                # ç”±äºæ•°æ®é›†æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿ
                # å¦‚æœå‘ç”Ÿäº†ï¼Œå¯èƒ½æ˜¯IDåŒ¹é…é—®é¢˜ï¼Œæˆ‘ä»¬è®¾ç½®ä¸ºä¸€ä¸ªå¾ˆå¤§çš„æ•°å­—
                best_rank = 1000
            best_query = expanded_query
            best_top_videos = top_k_videos.copy()
        
        search_results = {
            'initial_query': query,
            'turns': [],
            'final_query': expanded_query,
            'initial_rank': current_rank,
            'best_rank': best_rank,
            'final_rank': current_rank,
            'best_turn': -1,  # -1è¡¨ç¤ºåˆå§‹è½®
        }
        
        # è®°å½•æ¯è½®çš„top_kè§†é¢‘åˆ—è¡¨
        all_turns_top_videos = []
        all_turns_top_videos.append(top_k_videos)
        
        # å¦‚æœåˆå§‹æœç´¢å·²ç»è¾¾åˆ°æˆåŠŸé˜ˆå€¼ï¼Œå¯ä»¥æå‰ç»“æŸ
        if current_rank is not None and current_rank <= TOP_K:
            print(f"åˆå§‹æœç´¢å·²è¾¾åˆ°æˆåŠŸé˜ˆå€¼ï¼Œæ’åä¸º: {current_rank}")
            search_results['best_turn'] = -1
            return search_results, all_turns_top_videos
        
        # äº¤äº’å¾ªç¯
        for turn in range(max_turns):
            # ç”Ÿæˆé—®é¢˜ - ä½¿ç”¨å…¨éƒ¨å¯¹è¯å†å²
            question = self.generate_question(expanded_query, top_k_videos, conversation_history)
            
            # å¦‚æœæœ‰ç›®æ ‡è§†é¢‘ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç”¨æˆ·å›ç­”
            if target_video_id is not None:
                target_caption = ""
                # è·å–ç›®æ ‡è§†é¢‘caption (å…ˆç§»é™¤æ‰€æœ‰æ‰©å±•å)
                if isinstance(video_captions, dict):
                    # ç›´æ¥æŸ¥æ‰¾
                    if target_video_id in video_captions:
                        target_caption = video_captions[target_video_id]
                    # æ£€æŸ¥å­—å…¸ä¸­æ˜¯å¦æœ‰å¸¦æ‰©å±•åçš„ç‰ˆæœ¬
                    else:
                        for vid_id, caption in video_captions.items():
                            # å»é™¤æ‰©å±•åæ¯”è¾ƒ
                            if '.' in vid_id and os.path.splitext(vid_id)[0] == target_video_id:
                                target_caption = caption
                                break
                elif isinstance(video_captions, list):
                    # åˆ—è¡¨å¤„ç†
                    for item in video_captions:
                        if isinstance(item, tuple) and len(item) == 2:
                            vid_id, caption = item
                            # å»é™¤æ‰©å±•åæ¯”è¾ƒ
                            vid_base = os.path.splitext(vid_id)[0] if '.' in vid_id else vid_id
                            if vid_base == target_video_id:
                                target_caption = caption
                                break
                
                if target_caption:
                    answer = self.generate_answer(query, question, target_caption)
                else:
                    print(f"è­¦å‘Š: æ— æ³•æ‰¾åˆ°ç›®æ ‡è§†é¢‘ {target_video_id} çš„æè¿°")
                    answer = "I don't know."
            else:
                # å¦åˆ™ï¼Œè®©ç”¨æˆ·å›ç­”
                print(f"\nQuestion: {question}")
                answer = input("Your answer: ")
            
            # è®°å½•å¯¹è¯
            conversation_history.append({
                'question': question,
                'answer': answer
            })
            
            # æ›´æ–°æŸ¥è¯¢
            expanded_query = self.update_query(
                expanded_query, question, answer, 
                current_rank=current_rank, best_rank=best_rank
            )
            
            # ä½¿ç”¨æ›´æ–°åçš„æŸ¥è¯¢é‡æ–°æ£€ç´¢
            query_embedding = self.encode_text([expanded_query])
            top_k_videos = self.retrieve_videos(expanded_query, TOP_K, query_embedding)
            
            # ä¿å­˜æœ¬è½®çš„top_kè§†é¢‘
            all_turns_top_videos.append(top_k_videos)
            
            # å¦‚æœæœ‰ç›®æ ‡è§†é¢‘ï¼Œæ›´æ–°æ’å
            if target_video_id is not None:
                current_rank = self.find_target_rank(target_video_id, query_embedding)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ’å
                if current_rank is not None and current_rank < best_rank:
                    best_rank = current_rank
                    best_turn = turn
                    best_query = expanded_query
                    best_top_videos = top_k_videos.copy()
            
            # è®°å½•æœ¬è½®ç»“æœ
            turn_result = {
                'turn': turn + 1,
                'question': question,
                'answer': answer,
                'query': expanded_query,
                'rank': current_rank,
            }
            search_results['turns'].append(turn_result)
            
            # æ—¥å¿—è¾“å‡º
            status = f"Turn {turn+1}: "
            if current_rank is not None:
                status += f"Rank {current_rank}"
                if current_rank <= TOP_K:
                    status += " (in top-k)"
                if current_rank == best_rank:
                    status += " (new best)"
            status += f" | Query: {expanded_query}"
            print(status)
            
            # å¦‚æœæ’åä¸º1ï¼Œæå‰ç»“æŸå½“å‰è§†é¢‘çš„äº¤äº’
            if current_rank is not None and current_rank == 1:
                print(f"ç›®æ ‡è§†é¢‘æ’åç¬¬1ï¼Œæå‰ç»“æŸå½“å‰è§†é¢‘çš„äº¤äº’")
                break
        
        # æ›´æ–°æœ€ç»ˆç»“æœ - ä½¿ç”¨æœ€ä½³æ’åçš„ä¿¡æ¯
        search_results['final_query'] = best_query if best_turn >= 0 else expanded_query
        search_results['final_rank'] = current_rank
        search_results['best_rank'] = best_rank
        search_results['best_turn'] = best_turn
        
        return search_results, all_turns_top_videos

def main():
    # ==================== é…ç½®åŒºåŸŸ ====================
    # ä¿®æ”¹è¿™äº›è·¯å¾„æ¥é€‚é…ä½ çš„æ–°æ•°æ®
    
    # 1. è¾“å…¥æ–‡ä»¶è·¯å¾„ - ä¿®æ”¹ä¸ºä½ çš„æ–° xlsx æ–‡ä»¶è·¯å¾„
    captions_file = "/home/peterchen/M2/MER2024/llava_next_video_caption.xlsx"  # ä¿®æ”¹è¿™é‡Œ
    
    # 2. è¾“å‡ºæ–‡ä»¶è·¯å¾„ - ç»“æœä¿å­˜ä½ç½®
    output_file = "/home/peterchen/M2/æœ¬ç•ª/llava_next_video_deepseek/mer2024/search_results.xlsx"
    
    # 3. å¤„ç†èŒƒå›´ - å¤„ç†æ•´ä¸ªæ•°æ®é›†
    # start_idx = 0      # èµ·å§‹ç´¢å¼•
    # end_idx = 10       # ç»“æŸç´¢å¼•ï¼ˆåŒ…å«ï¼‰- å»ºè®®å…ˆç”¨å°èŒƒå›´æµ‹è¯•
    
    # 4. FAISS ç´¢å¼•è·¯å¾„ - ä¿å­˜ç´¢å¼•ä¾›ä¸‹æ¬¡ä½¿ç”¨
    faiss_index_path = "/home/peterchen/M2/æœ¬ç•ª/llava_next_video_deepseek/mer2024/faiss_index.index"
    id2video_path = "/home/peterchen/M2/æœ¬ç•ª/llava_next_video_deepseek/mer2024/id2video_mapping.pkl"
    
    # ==================== é…ç½®ç»“æŸ ====================
    
    print("=" * 60)
    print("äº¤äº’å¼è§†é¢‘æ£€ç´¢ç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {captions_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"å¤„ç†èŒƒå›´: æ•´ä¸ªæ•°æ®é›†")
    print(f"FAISSç´¢å¼•: {'è‡ªåŠ¨åˆ›å»º' if faiss_index_path is None else faiss_index_path}")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(output_file)
    os.makedirs(output_dir, exist_ok=True)
    print(f"è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}")
    
    # åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ - ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºFAISSç´¢å¼•
    print("\næ­£åœ¨åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ...")
    system = InteractiveVideoRetrievalSystem(captions_file, faiss_index_path, id2video_path)
    
    # è·å–DataFrame
    df = system.caption_df.copy()
    print(f"æˆåŠŸåŠ è½½ {len(df)} ä¸ªè§†é¢‘çš„caption")
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['name', 'model_caption', 'eng_caption']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        print(f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
        print(f"å½“å‰æ–‡ä»¶çš„åˆ—: {df.columns.tolist()}")
        return
    
    print(f"æ•°æ®æ–‡ä»¶åŒ…å«çš„åˆ—: {df.columns.tolist()}")
    
    # ç›´æ¥æ·»åŠ æ–°åˆ—
    df['interactive_initial_rank'] = None
    df['interactive_final_rank'] = None
    df['interactive_best_rank'] = None
    df['interactive_best_turn'] = None
    df['interactive_turns'] = None
    df['interactive_query'] = None
    df['top10_videos'] = None
    df['top10_scores'] = None
    df['target_rank'] = None  # ç›®æ ‡è§†é¢‘çš„å®é™…æ’å
    
    # ä¸ºæ¯è½®äº¤äº’æ·»åŠ åˆ—(æœ€å¤š5è½®)
    for i in range(1, MAX_ROUNDS + 1):
        df[f'question_{i}'] = None
        df[f'answer_{i}'] = None
        df[f'query_{i}'] = None
        df[f'rank_{i}'] = None
    
    # ç»Ÿè®¡å˜é‡
    initial_ranks = []
    final_ranks = []
    best_ranks = []
    
    # ä¿®æ”¹ä¸ºå­—å…¸å½¢å¼ï¼Œæ›´å®¹æ˜“é€šè¿‡IDæŸ¥æ‰¾
    all_captions = dict(zip(df['name'].tolist(), df['model_caption'].tolist()))
    print(f"åˆ›å»ºäº†åŒ…å« {len(all_captions)} ä¸ªè§†é¢‘çš„captionå­—å…¸")
    
    # ä¸»å¾ªç¯ - å¤„ç†æ•´ä¸ªæ•°æ®é›†
    total_samples = len(df)
    print(f"\nå¼€å§‹å¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼Œå…± {total_samples} ä¸ªæ ·æœ¬...")
    
    for i in tqdm(range(total_samples), total=total_samples):
        try:
            row = df.iloc[i]
            print(f"\n{'='*50}")
            print(f"å¤„ç†æ ·æœ¬ {i+1}/{total_samples}: {row['name']}")
            print(f"{'='*50}")
            
            # è·å–æŸ¥è¯¢
            query = row['eng_caption']
            target_id = row['name']
            
            print(f"ç›®æ ‡è§†é¢‘: {target_id}")
            print(f"åˆå§‹æŸ¥è¯¢: {query}")
            print(f"ç›®æ ‡è§†é¢‘æè¿°: {row['model_caption'][:100]}...")
            
            # è¿è¡Œäº¤äº’å¼æ£€ç´¢
            search_results, all_turns_top_videos = system.run_interactive_retrieval(
                query=query,
                video_captions=all_captions,
                target_video_id=target_id,
                max_turns=MAX_ROUNDS
            )
            
            # è·å–top10è§†é¢‘å’Œåˆ†æ•°
            final_turn_videos = []
            final_turn_scores = []
            
            # ç¡®å®šè¦ä½¿ç”¨å“ªä¸€è½®çš„ç»“æœ - ä½¿ç”¨æœ€ä½³æ’åçš„é‚£ä¸€è½®
            best_turn_idx = search_results['best_turn']
            
            # è·å–å¯¹åº”è½®æ¬¡çš„topè§†é¢‘
            if best_turn_idx >= 0 and best_turn_idx < len(all_turns_top_videos):
                # ä½¿ç”¨æœ€ä½³æ’åè½®æ¬¡çš„ç»“æœ
                result_videos = all_turns_top_videos[best_turn_idx + 1]  # +1æ˜¯å› ä¸ºall_turns_top_videosç¬¬ä¸€é¡¹æ˜¯åˆå§‹è½®
            else:
                # å¦‚æœæœ€ä½³æ˜¯åˆå§‹è½®æˆ–æ²¡æœ‰æ›´å¥½çš„ç»“æœï¼Œä½¿ç”¨æœ€åä¸€è½®
                result_videos = all_turns_top_videos[-1]
            
            # æå–å‰10ä¸ªè§†é¢‘IDå’Œåˆ†æ•°
            for video_info in result_videos[:10]:
                if isinstance(video_info, dict):
                    video_id = video_info.get('video_id', '')
                    score = video_info.get('score', 0.0)
                    final_turn_videos.append(video_id)
                    final_turn_scores.append(score)
            
            # ä¿å­˜åŸºæœ¬ç»“æœ
            df.loc[i, 'interactive_initial_rank'] = search_results['initial_rank']
            df.loc[i, 'interactive_final_rank'] = search_results['final_rank']
            df.loc[i, 'interactive_best_rank'] = search_results['best_rank']
            df.loc[i, 'interactive_best_turn'] = search_results['best_turn']
            df.loc[i, 'interactive_turns'] = len(search_results['turns'])
            df.loc[i, 'interactive_query'] = search_results['final_query']
            df.loc[i, 'top10_videos'] = str(final_turn_videos)
            df.loc[i, 'top10_scores'] = str(final_turn_scores)
            df.loc[i, 'target_rank'] = search_results['best_rank'] # ä¿å­˜ç›®æ ‡è§†é¢‘çš„å®é™…æ’å
            
            # ä¿å­˜æ¯è½®äº¤äº’çš„ä¿¡æ¯
            completed_turns = len(search_results['turns'])
            for turn_num in range(1, MAX_ROUNDS + 1):
                if turn_num <= completed_turns:
                    # æœ‰å®é™…äº¤äº’çš„è½®æ¬¡
                    turn_data = search_results['turns'][turn_num - 1]
                    df.loc[i, f'question_{turn_num}'] = turn_data.get('question', '')
                    df.loc[i, f'answer_{turn_num}'] = turn_data.get('answer', '')
                    df.loc[i, f'query_{turn_num}'] = turn_data.get('query', '')
                    df.loc[i, f'rank_{turn_num}'] = turn_data.get('rank', '')
                else:
                    # æå‰åœæ­¢åçš„è½®æ¬¡ï¼Œquestionå’Œanswerè®°ä¸ºNoneï¼Œrankè®°ä¸º1
                    df.loc[i, f'question_{turn_num}'] = None
                    df.loc[i, f'answer_{turn_num}'] = None
                    df.loc[i, f'query_{turn_num}'] = None
                    df.loc[i, f'rank_{turn_num}'] = 1
            
            print(f"âœ“ ä¿å­˜äº† {len(search_results['turns'])} è½®äº¤äº’")
            print(f"âœ“ åˆå§‹æ’å: {search_results['initial_rank']} â†’ æœ€ä½³æ’å: {search_results['best_rank']}")
            
            # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            if search_results['initial_rank'] is not None:
                initial_ranks.append(search_results['initial_rank'])
            if search_results['final_rank'] is not None:
                final_ranks.append(search_results['final_rank'])
            if search_results['best_rank'] is not None:
                best_ranks.append(search_results['best_rank'])
            
            # æ¯å¤„ç†10ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
            if (i + 1) % 10 == 0:
                df.to_excel(output_file, index=False)
                print(f"âœ“ å·²ä¿å­˜ä¸­é—´ç»“æœåˆ°: {output_file}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    print(f"\n{'='*60}")
    print(f"ä¿å­˜æœ€ç»ˆç»“æœåˆ°: {output_file}")
    df.to_excel(output_file, index=False)
    print(f"âœ“ å·²ä¿å­˜æ‰€æœ‰ç»“æœ")
    
    # ç®€åŒ–çš„ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("ç»“æœç»Ÿè®¡:")
    print("="*60)
    if initial_ranks:
        print(f"å¹³å‡åˆå§‹æ’å: {np.mean(initial_ranks):.2f}")
    if best_ranks:
        print(f"å¹³å‡æœ€ä½³æ’å: {np.mean(best_ranks):.2f}")
    if final_ranks:
        print(f"å¹³å‡æœ€ç»ˆæ’å: {np.mean(final_ranks):.2f}")
    
    # å¬å›ç‡ç»Ÿè®¡
    ranks_to_evaluate = [10, 50, 100, 200]
    
    print("\nå¬å›ç‡ç»Ÿè®¡:")
    for k in ranks_to_evaluate:
        if initial_ranks:
            initial_r_at_k = sum(r <= k for r in initial_ranks) / len(initial_ranks) * 100
            print(f"åˆå§‹ R@{k}: {initial_r_at_k:.2f}%")
        
        if best_ranks:
            best_r_at_k = sum(r <= k for r in best_ranks) / len(best_ranks) * 100
            print(f"æœ€ä½³ R@{k}: {best_r_at_k:.2f}%")
    
    print("\n" + "="*60)
    print("ğŸ‰ å®Œæˆæ‰€æœ‰å¤„ç†!")
    print("="*60)
    
if __name__ == "__main__":
    main()
                    
                                    
                                 
        
        

        
